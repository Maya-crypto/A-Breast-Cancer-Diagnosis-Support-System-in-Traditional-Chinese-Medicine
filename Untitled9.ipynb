{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKz9QNFDTNCAO4fAcIb/1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maya-crypto/A-Breast-Cancer-Diagnosis-Support-System-in-Traditional-Chinese-Medicine/blob/test/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# üìç Chemin vers le fichier zip (tu peux l'importer via l'interface Colab)\n",
        "zip_path = '/content/train.zip'  # √† adapter\n",
        "extract_to = '/content/train'  # dossier de destination\n",
        "\n",
        "# üìÅ Cr√©ation du dossier de destination s'il n'existe pas\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# üîì D√©compression\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"‚úÖ Fichier d√©zipp√© dans : {extract_to}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgyZHK5qTDw1",
        "outputId": "4233fd92-30fb-43b1-f3de-eddd23381d0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fichier d√©zipp√© dans : /content/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR8WlWIAS6P6",
        "outputId": "12ff3c4c-3d05-488d-9156-e627c3214a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\n",
            "D√©tection YOLO + Machine Learning pour Cancer du Sein\n",
            "SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\n",
            "================================================================================\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 1\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/mon_modele.pt\n",
            "Dossier images d'entra√Ænement: /content/train/train/images\n",
            "Installation d'ultralytics...\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 80\n",
            "Distribution des labels:\n",
            "  - healthy: 38\n",
            "  - advanced: 19\n",
            "  - early: 23\n",
            "\n",
            "Extraction des features...\n",
            "  Progression: 0/80\n",
            "  Progression: 10/80\n",
            "  Progression: 20/80\n",
            "  Progression: 30/80\n",
            "  Progression: 40/80\n",
            "  Progression: 50/80\n",
            "  Progression: 60/80\n",
            "  Progression: 70/80\n",
            "\n",
            "Features extraites: (80, 67)\n",
            "Features par image: 67\n",
            "\n",
            "ENTRAINEMENT DES CLASSIFICATEURS\n",
            "============================================================\n",
            "\n",
            "Entra√Ænement RandomForest...\n",
            "  Accuracy: 0.9375\n",
            "  CV Score: 0.7949 (+/- 0.1716)\n",
            "\n",
            "Rapport d√©taill√© RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    advanced       1.00      1.00      1.00         4\n",
            "       early       1.00      0.80      0.89         5\n",
            "     healthy       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.96      0.93      0.94        16\n",
            "weighted avg       0.95      0.94      0.94        16\n",
            "\n",
            "\n",
            "Entra√Ænement XGBoost...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7962 (+/- 0.1606)\n",
            "\n",
            "Entra√Ænement SVM...\n",
            "  Accuracy: 0.9375\n",
            "  CV Score: 0.8115 (+/- 0.1890)\n",
            "\n",
            "Entra√Ænement MLP...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7628 (+/- 0.2364)\n",
            "\n",
            "Entra√Ænement GradientBoosting...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7667 (+/- 0.2142)\n",
            "\n",
            "üèÜ MEILLEUR MODELE: SVM\n",
            "   Accuracy: 0.9375\n",
            "   CV Score: 0.8115\n",
            "\n",
            "Sauvegarde mod√®les dans mtc_classifiers\n",
            "‚úÖ Mod√®les sauvegard√©s\n",
            "\n",
            "‚úÖ ENTRAINEMENT TERMINE!\n",
            "Mod√®les sauvegard√©s dans: mtc_classifiers\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/mon_modele.pt\n",
            "Chemin image: /content/train/train/images/ABC_2_png_segmented_jpg.rf.8005845c95e7e0ffe3871d375d41eb6c.jpg\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image: ABC_2_png_segmented_jpg.rf.8005845c95e7e0ffe3871d375d41eb6c.jpg\n",
            "üéØ Pr√©diction: ADVANCED\n",
            "üìä Confiance: 82.19%\n",
            "ü§ñ Classificateur: SVM\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.8219 (82.19%)\n",
            "  - early: 0.1266 (12.66%)\n",
            "  - healthy: 0.0514 (5.14%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: early (0.391)\n",
            "  - XGBoost: advanced (0.691)\n",
            "  - SVM: advanced (0.370)\n",
            "  - MLP: advanced (1.000)\n",
            "  - GradientBoosting: early (0.511)\n",
            "\n",
            "üìä Visualisation: mtc_results/hybrid_diag_ABC_2_png_segmented_jpg.rf.8005845c95e7e0ffe3871d375d41eb6c_20250621_211746.png\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/mon_modele.pt\n",
            "Chemin image: /content/train/train/images/EBC_3_png_segmented_jpg.rf.6a45a063b8fcd55a3439bf72fe5e661a.jpg\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image: EBC_3_png_segmented_jpg.rf.6a45a063b8fcd55a3439bf72fe5e661a.jpg\n",
            "üéØ Pr√©diction: EARLY\n",
            "üìä Confiance: 85.48%\n",
            "ü§ñ Classificateur: SVM\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.0707 (7.07%)\n",
            "  - early: 0.8548 (85.48%)\n",
            "  - healthy: 0.0745 (7.45%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: early (0.399)\n",
            "  - XGBoost: early (0.693)\n",
            "  - SVM: advanced (0.370)\n",
            "  - MLP: early (1.000)\n",
            "  - GradientBoosting: early (1.000)\n",
            "\n",
            "üìä Visualisation: mtc_results/hybrid_diag_EBC_3_png_segmented_jpg.rf.6a45a063b8fcd55a3439bf72fe5e661a_20250621_211935.png\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 1\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/train/train/labels\n",
            "Dossier images d'entra√Ænement: /content/train/train/images/healthy_18_png_segmented_jpg.rf.dcbe04bd11e3a5a1556d57c484e04be7.jpg\n",
            "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3-1953035634.py\", line 820, in main_hybrid\n",
            "    X, y = hybrid_system.prepare_training_data(train_folder)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3-1953035634.py\", line 376, in prepare_training_data\n",
            "    print(f\"Features par image: {X.shape[1]}\")\n",
            "                                 ~~~~~~~^^^\n",
            "IndexError: tuple index out of range\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 0\n",
            "Distribution des labels:\n",
            "\n",
            "Extraction des features...\n",
            "\n",
            "Features extraites: (0,)\n",
            "‚ùå ERREUR: tuple index out of range\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 1\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/mon_modele.pt\n",
            "Dossier images d'entra√Ænement: /content/train/train/images/healthy_2_png_segmented_jpg.rf.83df3613866fe49ec911801361fc0a63.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3-1953035634.py\", line 820, in main_hybrid\n",
            "    X, y = hybrid_system.prepare_training_data(train_folder)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3-1953035634.py\", line 376, in prepare_training_data\n",
            "    print(f\"Features par image: {X.shape[1]}\")\n",
            "                                 ~~~~~~~^^^\n",
            "IndexError: tuple index out of range\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 0\n",
            "Distribution des labels:\n",
            "\n",
            "Extraction des features...\n",
            "\n",
            "Features extraites: (0,)\n",
            "‚ùå ERREUR: tuple index out of range\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO: /content/mon_modele.pt\n",
            "Chemin image: /content/train/train/images/healthy_4_png_segmented_jpg.rf.72a89ed9986e658ad3fe57a5fb6e0e5a.jpg\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image: healthy_4_png_segmented_jpg.rf.72a89ed9986e658ad3fe57a5fb6e0e5a.jpg\n",
            "üéØ Pr√©diction: HEALTHY\n",
            "üìä Confiance: 92.00%\n",
            "ü§ñ Classificateur: SVM\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.0234 (2.34%)\n",
            "  - early: 0.0566 (5.66%)\n",
            "  - healthy: 0.9200 (92.00%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: healthy (0.878)\n",
            "  - XGBoost: healthy (0.981)\n",
            "  - SVM: advanced (0.370)\n",
            "  - MLP: healthy (1.000)\n",
            "  - GradientBoosting: early (0.886)\n",
            "\n",
            "üìä Visualisation: mtc_results/hybrid_diag_healthy_4_png_segmented_jpg.rf.72a89ed9986e658ad3fe57a5fb6e0e5a_20250621_212223.png\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "‚ö†Ô∏è Interruption utilisateur\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "\n",
        "# Configuration syst√®me optimis√©e\n",
        "CONFIG = {\n",
        "    'base_dir': '.',\n",
        "    'output_dir': 'mtc_output',\n",
        "    'model_dir': 'mtc_models',\n",
        "    'results_dir': 'mtc_results',\n",
        "    'classifier_dir': 'mtc_classifiers',\n",
        "    'train_split': 0.8,\n",
        "    'epochs': 200,\n",
        "    'batch_size': 16,\n",
        "    'imgsz': 640,\n",
        "    'patience': 50,\n",
        "    'conf_threshold': 0.15,\n",
        "    'iou_threshold': 0.3,\n",
        "    'augmentation_factor': 8,\n",
        "    'target_accuracy': 0.85,\n",
        "    'random_seed': 42,\n",
        "    'lr0': 0.0008,\n",
        "    'weight_decay': 0.001,\n",
        "    'mosaic': 0.8,\n",
        "    'mixup': 0.1,\n",
        "    'copy_paste': 0.1,\n",
        "}\n",
        "\n",
        "# Classes YOLO (16 classes)\n",
        "CLASS_NAMES = [\n",
        "    'Ecchymoses', 'Eduit_jaune_epais', 'Eduit_jaune_mince', 'Fissure',\n",
        "    'Langue_normal', 'Langue_pale', 'Langue_petite', 'Langue_rose',\n",
        "    'Langue_rouge', 'Langue_rouge_foncee', 'enduit_blanc_epais',\n",
        "    'enduit_blanc_mince', 'langue_ganfelee', 'red_dot',\n",
        "    'salive_humide', 'salive_normale'\n",
        "]\n",
        "\n",
        "# Zones MTC\n",
        "TONGUE_ZONES = {\n",
        "    'kidney': {\n",
        "        'name': 'Rein',\n",
        "        'coords': [(0.2, 0), (0.8, 0), (0.8, 0.15), (0.2, 0.15)],\n",
        "        'color': (75, 0, 130)\n",
        "    },\n",
        "    'liver_gall_right': {\n",
        "        'name': 'Foie-VB Droit',\n",
        "        'coords': [(0, 0.15), (0.3, 0.15), (0.3, 0.65), (0, 0.65)],\n",
        "        'color': (34, 139, 34)\n",
        "    },\n",
        "    'liver_gall_left': {\n",
        "        'name': 'Foie-VB Gauche',\n",
        "        'coords': [(0.7, 0.15), (1, 0.15), (1, 0.65), (0.7, 0.65)],\n",
        "        'color': (50, 205, 50)\n",
        "    },\n",
        "    'spleen_stomach': {\n",
        "        'name': 'Rate-Estomac',\n",
        "        'coords': [(0.3, 0.15), (0.7, 0.15), (0.7, 0.65), (0.3, 0.65)],\n",
        "        'color': (255, 215, 0)\n",
        "    },\n",
        "    'heart_lung': {\n",
        "        'name': 'Coeur-Poumon',\n",
        "        'coords': [(0.2, 0.65), (0.8, 0.65), (0.8, 1), (0.2, 1)],\n",
        "        'color': (220, 20, 60)\n",
        "    }\n",
        "}\n",
        "\n",
        "class YOLOFeatureExtractor:\n",
        "    \"\"\"Extracteur de features bas√© sur les d√©tections YOLO\"\"\"\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "        except ImportError:\n",
        "            print(\"Installation d'ultralytics...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ultralytics'])\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "        \"\"\"Extrait features compl√®tes d'une image\"\"\"\n",
        "        try:\n",
        "            results = self.model(image_path, conf=CONFIG['conf_threshold'],\n",
        "                               iou=CONFIG['iou_threshold'], verbose=False)\n",
        "\n",
        "            image = cv2.imread(str(image_path))\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # Initialiser features\n",
        "            features = self._initialize_features()\n",
        "\n",
        "            # Traiter d√©tections\n",
        "            detections = []\n",
        "            for r in results:\n",
        "                if r.boxes is not None:\n",
        "                    for box in r.boxes:\n",
        "                        bbox = box.xyxy[0].cpu().numpy()\n",
        "                        conf = float(box.conf)\n",
        "                        cls = int(box.cls)\n",
        "\n",
        "                        if cls < len(CLASS_NAMES):\n",
        "                            detection = {\n",
        "                                'bbox': bbox,\n",
        "                                'confidence': conf,\n",
        "                                'class': cls,\n",
        "                                'class_name': CLASS_NAMES[cls]\n",
        "                            }\n",
        "                            detections.append(detection)\n",
        "\n",
        "            # Extraire features des d√©tections\n",
        "            features = self._extract_detection_features(detections, features, w, h)\n",
        "            features = self._extract_spatial_features(detections, features, w, h)\n",
        "            features = self._extract_statistical_features(detections, features)\n",
        "            features = self._extract_zone_features(detections, features, w, h)\n",
        "\n",
        "            return np.array(list(features.values()))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur extraction features: {e}\")\n",
        "            return np.zeros(self._get_feature_count())\n",
        "\n",
        "    def _initialize_features(self):\n",
        "        \"\"\"Initialise toutes les features √† 0\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Features par classe (confidence max et count)\n",
        "        for class_name in CLASS_NAMES:\n",
        "            features[f'{class_name}_max_conf'] = 0.0\n",
        "            features[f'{class_name}_count'] = 0.0\n",
        "            features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        # Features spatiales\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            features[f'{zone}_detection_count'] = 0.0\n",
        "            features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        # Features statistiques globales\n",
        "        features['total_detections'] = 0.0\n",
        "        features['avg_confidence_all'] = 0.0\n",
        "        features['std_confidence'] = 0.0\n",
        "        features['detection_density'] = 0.0\n",
        "\n",
        "        # Features morphologiques\n",
        "        features['tongue_area_ratio'] = 0.0\n",
        "        features['detection_spread_x'] = 0.0\n",
        "        features['detection_spread_y'] = 0.0\n",
        "\n",
        "        # Features de co-occurrence\n",
        "        features['pathological_combinations'] = 0.0\n",
        "        features['healthy_indicators'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_detection_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features bas√©es sur les d√©tections\"\"\"\n",
        "        class_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            class_name = det['class_name']\n",
        "            conf = det['confidence']\n",
        "            class_detections[class_name].append(conf)\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            confs = class_detections[class_name]\n",
        "            if confs:\n",
        "                features[f'{class_name}_max_conf'] = max(confs)\n",
        "                features[f'{class_name}_count'] = len(confs)\n",
        "                features[f'{class_name}_avg_conf'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{class_name}_max_conf'] = 0.0\n",
        "                features[f'{class_name}_count'] = 0.0\n",
        "                features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_spatial_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features spatiales et de zones\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        # Calculer centroids normalis√©s\n",
        "        centroids = []\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "            centroids.append((cx, cy))\n",
        "\n",
        "        # Spread spatial\n",
        "        if centroids:\n",
        "            x_coords = [c[0] for c in centroids]\n",
        "            y_coords = [c[1] for c in centroids]\n",
        "            features['detection_spread_x'] = np.std(x_coords) if len(x_coords) > 1 else 0\n",
        "            features['detection_spread_y'] = np.std(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_statistical_features(self, detections, features):\n",
        "        \"\"\"Extrait features statistiques globales\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        confidences = [det['confidence'] for det in detections]\n",
        "\n",
        "        features['total_detections'] = len(detections)\n",
        "        features['avg_confidence_all'] = np.mean(confidences)\n",
        "        features['std_confidence'] = np.std(confidences)\n",
        "        features['detection_density'] = len(detections) / 100.0  # Normalis√©\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_zone_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features par zone MTC\"\"\"\n",
        "        zone_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "\n",
        "            zone = self._find_zone(cx, cy)\n",
        "            if zone:\n",
        "                zone_detections[zone].append(det['confidence'])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            confs = zone_detections[zone]\n",
        "            if confs:\n",
        "                features[f'{zone}_detection_count'] = len(confs)\n",
        "                features[f'{zone}_avg_confidence'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{zone}_detection_count'] = 0.0\n",
        "                features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _find_zone(self, x, y):\n",
        "        \"\"\"Trouve zone pour coordonn√©es\"\"\"\n",
        "        for zone_name, zone_info in TONGUE_ZONES.items():\n",
        "            if self._point_in_polygon(x, y, zone_info['coords']):\n",
        "                return zone_name\n",
        "        return None\n",
        "\n",
        "    def _point_in_polygon(self, x, y, coords):\n",
        "        \"\"\"Test point dans polygone\"\"\"\n",
        "        n = len(coords)\n",
        "        inside = False\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            xi, yi = coords[i]\n",
        "            xj, yj = coords[j]\n",
        "            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "    def _get_feature_count(self):\n",
        "        \"\"\"Retourne le nombre total de features\"\"\"\n",
        "        # 3 features par classe (48) + 10 zones x 2 (20) + 7 globales + 2 morpho + 2 co-occur\n",
        "        return len(CLASS_NAMES) * 3 + len(TONGUE_ZONES) * 2 + 7 + 2 + 2\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        \"\"\"Retourne noms des features\"\"\"\n",
        "        names = []\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            names.extend([\n",
        "                f'{class_name}_max_conf',\n",
        "                f'{class_name}_count',\n",
        "                f'{class_name}_avg_conf'\n",
        "            ])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            names.extend([\n",
        "                f'{zone}_detection_count',\n",
        "                f'{zone}_avg_confidence'\n",
        "            ])\n",
        "\n",
        "        # Features globales\n",
        "        names.extend([\n",
        "            'total_detections', 'avg_confidence_all', 'std_confidence',\n",
        "            'detection_density', 'tongue_area_ratio', 'detection_spread_x',\n",
        "            'detection_spread_y', 'pathological_combinations', 'healthy_indicators'\n",
        "        ])\n",
        "\n",
        "        return names\n",
        "\n",
        "class HybridClassificationSystem:\n",
        "    \"\"\"Syst√®me hybride YOLO + Classification ML\"\"\"\n",
        "\n",
        "    def __init__(self, yolo_model_path):\n",
        "        self.feature_extractor = YOLOFeatureExtractor(yolo_model_path)\n",
        "        self.classifiers = {}\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.is_trained = False\n",
        "\n",
        "        # Cr√©er dossier pour sauvegardes\n",
        "        self.classifier_dir = Path(CONFIG['classifier_dir'])\n",
        "        self.classifier_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def prepare_training_data(self, image_folder, labels_file=None):\n",
        "        \"\"\"Pr√©pare donn√©es d'entra√Ænement\"\"\"\n",
        "        print(\"PREPARATION DES DONNEES D'ENTRAINEMENT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "\n",
        "        # Collecter images et labels\n",
        "        for img_path in Path(image_folder).glob('*.jpg'):\n",
        "            image_paths.append(img_path)\n",
        "\n",
        "            # Extraire label du nom de fichier (comme dans votre code original)\n",
        "            label = self._extract_label_from_filename(img_path.name)\n",
        "            labels.append(label)\n",
        "\n",
        "        print(f\"Images trouv√©es: {len(image_paths)}\")\n",
        "\n",
        "        # Distribution des labels\n",
        "        label_counts = defaultdict(int)\n",
        "        for label in labels:\n",
        "            label_counts[label] += 1\n",
        "\n",
        "        print(\"Distribution des labels:\")\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"  - {label}: {count}\")\n",
        "\n",
        "        # Extraire features\n",
        "        print(\"\\nExtraction des features...\")\n",
        "        features_list = []\n",
        "        valid_labels = []\n",
        "\n",
        "        for i, (img_path, label) in enumerate(zip(image_paths, labels)):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"  Progression: {i}/{len(image_paths)}\")\n",
        "\n",
        "            features = self.feature_extractor.extract_features(img_path)\n",
        "            if features is not None and not np.all(features == 0):\n",
        "                features_list.append(features)\n",
        "                valid_labels.append(label)\n",
        "\n",
        "        X = np.array(features_list)\n",
        "        y = np.array(valid_labels)\n",
        "\n",
        "        print(f\"\\nFeatures extraites: {X.shape}\")\n",
        "        print(f\"Features par image: {X.shape[1]}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train_classifiers(self, X, y):\n",
        "        \"\"\"Entra√Æne plusieurs classificateurs\"\"\"\n",
        "        print(\"\\nENTRAINEMENT DES CLASSIFICATEURS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Encoder labels\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "\n",
        "        # Split train/test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=CONFIG['random_seed'],\n",
        "            stratify=y_encoded\n",
        "        )\n",
        "\n",
        "        # Normaliser features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # D√©finir classificateurs\n",
        "        classifiers_config = {\n",
        "            'RandomForest': {\n",
        "                'model': RandomForestClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=15,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model': xgb.XGBClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'SVM': {\n",
        "                'model': SVC(\n",
        "                    kernel='rbf',\n",
        "                    C=10,\n",
        "                    gamma='scale',\n",
        "                    probability=True,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'MLP': {\n",
        "                'model': MLPClassifier(\n",
        "                    hidden_layer_sizes=(128, 64, 32),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.001,\n",
        "                    learning_rate='adaptive',\n",
        "                    max_iter=500,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'GradientBoosting': {\n",
        "                'model': GradientBoostingClassifier(\n",
        "                    n_estimators=200,\n",
        "                    learning_rate=0.1,\n",
        "                    max_depth=8,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Entra√Æner et √©valuer chaque classificateur\n",
        "        results = {}\n",
        "\n",
        "        for name, config in classifiers_config.items():\n",
        "            print(f\"\\nEntra√Ænement {name}...\")\n",
        "\n",
        "            model = config['model']\n",
        "\n",
        "            if config['use_scaling']:\n",
        "                X_train_input = X_train_scaled\n",
        "                X_test_input = X_test_scaled\n",
        "            else:\n",
        "                X_train_input = X_train\n",
        "                X_test_input = X_test\n",
        "\n",
        "            # Entra√Æner\n",
        "            model.fit(X_train_input, y_train)\n",
        "\n",
        "            # Pr√©dictions\n",
        "            y_pred = model.predict(X_test_input)\n",
        "            y_pred_proba = model.predict_proba(X_test_input)\n",
        "\n",
        "            # M√©triques\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            # Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_input, y_train, cv=5)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'accuracy': accuracy,\n",
        "                'cv_mean': cv_scores.mean(),\n",
        "                'cv_std': cv_scores.std(),\n",
        "                'use_scaling': config['use_scaling']\n",
        "            }\n",
        "\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "            # Rapport d√©taill√© pour le meilleur mod√®le\n",
        "            if name == 'RandomForest':  # Afficher d√©tails pour RF\n",
        "                print(f\"\\nRapport d√©taill√© {name}:\")\n",
        "                class_names = self.label_encoder.classes_\n",
        "                print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "        # S√©lectionner meilleur mod√®le\n",
        "        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
        "        best_model_info = results[best_name]\n",
        "\n",
        "        print(f\"\\nüèÜ MEILLEUR MODELE: {best_name}\")\n",
        "        print(f\"   Accuracy: {best_model_info['accuracy']:.4f}\")\n",
        "        print(f\"   CV Score: {best_model_info['cv_mean']:.4f}\")\n",
        "\n",
        "        # Sauvegarder mod√®les\n",
        "        self.classifiers = results\n",
        "        self.best_classifier_name = best_name\n",
        "        self.is_trained = True\n",
        "\n",
        "        # Sauvegarder sur disque\n",
        "        self.save_models()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict(self, image_path, return_probabilities=False):\n",
        "        \"\"\"Pr√©diction hybride YOLO + Classification\"\"\"\n",
        "        if not self.is_trained:\n",
        "            self.load_models()\n",
        "\n",
        "        # Extraire features avec YOLO\n",
        "        features = self.feature_extractor.extract_features(image_path)\n",
        "\n",
        "        if features is None or np.all(features == 0):\n",
        "            return {\n",
        "                'prediction': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'probabilities': {},\n",
        "                'error': 'Aucune feature extraite'\n",
        "            }\n",
        "\n",
        "        # Utiliser le meilleur classificateur\n",
        "        best_clf_info = self.classifiers[self.best_classifier_name]\n",
        "        model = best_clf_info['model']\n",
        "        use_scaling = best_clf_info['use_scaling']\n",
        "\n",
        "        # Pr√©parer features\n",
        "        features_reshaped = features.reshape(1, -1)\n",
        "        if use_scaling:\n",
        "            features_reshaped = self.scaler.transform(features_reshaped)\n",
        "\n",
        "        # Pr√©diction\n",
        "        prediction_encoded = model.predict(features_reshaped)[0]\n",
        "        prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "\n",
        "        # Probabilit√©s\n",
        "        probabilities = model.predict_proba(features_reshaped)[0]\n",
        "        prob_dict = {}\n",
        "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
        "            prob_dict[class_name] = probabilities[i]\n",
        "\n",
        "        confidence = max(probabilities)\n",
        "\n",
        "        result = {\n",
        "            'prediction': prediction,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': prob_dict,\n",
        "            'classifier_used': self.best_classifier_name\n",
        "        }\n",
        "\n",
        "        if return_probabilities:\n",
        "            result['all_classifier_predictions'] = self._get_ensemble_predictions(features_reshaped)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _get_ensemble_predictions(self, features):\n",
        "        \"\"\"Pr√©dictions ensemble de tous les classificateurs\"\"\"\n",
        "        ensemble_results = {}\n",
        "\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model = clf_info['model']\n",
        "            use_scaling = clf_info['use_scaling']\n",
        "\n",
        "            features_input = self.scaler.transform(features) if use_scaling else features\n",
        "\n",
        "            prediction_encoded = model.predict(features_input)[0]\n",
        "            prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "            probabilities = model.predict_proba(features_input)[0]\n",
        "\n",
        "            ensemble_results[name] = {\n",
        "                'prediction': prediction,\n",
        "                'confidence': max(probabilities),\n",
        "                'probabilities': dict(zip(self.label_encoder.classes_, probabilities))\n",
        "            }\n",
        "\n",
        "        return ensemble_results\n",
        "\n",
        "    def save_models(self):\n",
        "        \"\"\"Sauvegarde mod√®les et preprocessing\"\"\"\n",
        "        print(f\"\\nSauvegarde mod√®les dans {self.classifier_dir}\")\n",
        "\n",
        "        # Sauvegarder chaque classificateur\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            joblib.dump(clf_info['model'], model_path)\n",
        "\n",
        "        # Sauvegarder preprocessing\n",
        "        joblib.dump(self.scaler, self.classifier_dir / \"scaler.joblib\")\n",
        "        joblib.dump(self.label_encoder, self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Sauvegarder config\n",
        "        config = {\n",
        "            'best_classifier': self.best_classifier_name,\n",
        "            'classifiers_config': {name: {'use_scaling': info['use_scaling']}\n",
        "                                 for name, info in self.classifiers.items()},\n",
        "            'feature_names': self.feature_extractor.get_feature_names()\n",
        "        }\n",
        "\n",
        "        with open(self.classifier_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"‚úÖ Mod√®les sauvegard√©s\")\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Charge mod√®les sauvegard√©s\"\"\"\n",
        "        config_path = self.classifier_dir / \"config.json\"\n",
        "\n",
        "        if not config_path.exists():\n",
        "            raise FileNotFoundError(\"Aucun mod√®le sauvegard√© trouv√©\")\n",
        "\n",
        "        print(\"Chargement mod√®les sauvegard√©s...\")\n",
        "\n",
        "        # Charger config\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        self.best_classifier_name = config['best_classifier']\n",
        "\n",
        "        # Charger preprocessing\n",
        "        self.scaler = joblib.load(self.classifier_dir / \"scaler.joblib\")\n",
        "        self.label_encoder = joblib.load(self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Charger classificateurs\n",
        "        self.classifiers = {}\n",
        "        for name, clf_config in config['classifiers_config'].items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            if model_path.exists():\n",
        "                model = joblib.load(model_path)\n",
        "                self.classifiers[name] = {\n",
        "                    'model': model,\n",
        "                    'use_scaling': clf_config['use_scaling']\n",
        "                }\n",
        "\n",
        "        self.is_trained = True\n",
        "        print(\"‚úÖ Mod√®les charg√©s\")\n",
        "\n",
        "    def _extract_label_from_filename(self, filename):\n",
        "        \"\"\"Extrait label du nom de fichier\"\"\"\n",
        "        filename_lower = filename.lower()\n",
        "\n",
        "        if any(keyword in filename_lower for keyword in ['healthy', 'sain', 'normal']):\n",
        "            return 'healthy'\n",
        "        elif any(keyword in filename_lower for keyword in ['ebc', 'early', 'precoce']):\n",
        "            return 'early'\n",
        "        elif any(keyword in filename_lower for keyword in ['abc', 'advanced', 'avance']):\n",
        "            return 'advanced'\n",
        "        elif any(keyword in filename_lower for keyword in ['real']):\n",
        "            if any(keyword in filename_lower for keyword in ['1', 'one', 'first']):\n",
        "                return 'healthy'\n",
        "            elif any(keyword in filename_lower for keyword in ['2', 'two', 'second']):\n",
        "                return 'early'\n",
        "            elif any(keyword in filename_lower for keyword in ['3', 'three', 'third']):\n",
        "                return 'advanced'\n",
        "            else:\n",
        "                return 'unknown'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "class HybridDiagnosticVisualizer:\n",
        "    \"\"\"Visualiseur pour syst√®me hybride\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results_dir = Path(CONFIG['results_dir'])\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def create_comprehensive_visualization(self, image_path, yolo_detections, ml_result):\n",
        "        \"\"\"Cr√©e visualisation compl√®te\"\"\"\n",
        "        image = cv2.imread(str(image_path))\n",
        "\n",
        "        fig = plt.figure(figsize=(24, 8))\n",
        "\n",
        "        # Image avec d√©tections YOLO\n",
        "        ax1 = plt.subplot(1, 4, 1)\n",
        "        ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        ax1.set_title('D√©tections YOLO', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Ajouter bounding boxes (si disponibles)\n",
        "        # Cette partie n√©cessiterait les d√©tections brutes de YOLO\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # Graphique des probabilit√©s ML\n",
        "        ax2 = plt.subplot(1, 4, 2)\n",
        "        probs = ml_result['probabilities']\n",
        "        classes = list(probs.keys())\n",
        "        prob_values = list(probs.values())\n",
        "\n",
        "        colors = ['green' if cls == 'healthy' else 'orange' if cls == 'early' else 'red'\n",
        "                 for cls in classes]\n",
        "\n",
        "        bars = ax2.bar(classes, prob_values, color=colors, alpha=0.7)\n",
        "        ax2.set_title('Probabilit√©s ML', fontsize=14, fontweight='bold')\n",
        "        ax2.set_ylabel('Probabilit√©')\n",
        "        ax2.set_ylim(0, 1)\n",
        "\n",
        "        # Ajouter valeurs sur barres\n",
        "        for bar, prob in zip(bars, prob_values):\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{prob:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "        # R√©sultat final\n",
        "        ax3 = plt.subplot(1, 4, 3)\n",
        "        ax3.axis('off')\n",
        "\n",
        "        prediction = ml_result['prediction']\n",
        "        confidence = ml_result['confidence']\n",
        "        classifier = ml_result['classifier_used']\n",
        "\n",
        "        # Couleur selon pr√©diction\n",
        "        pred_color = 'green' if prediction == 'healthy' else 'orange' if prediction == 'early' else 'red'\n",
        "\n",
        "        ax3.text(0.5, 0.9, 'DIAGNOSTIC HYBRIDE', ha='center', fontsize=16,\n",
        "                weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        ax3.text(0.5, 0.7, f'Pr√©diction: {prediction.upper()}', ha='center',\n",
        "                fontsize=14, color=pred_color, weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        ax3.text(0.5, 0.5, f'Confiance: {confidence:.2%}', ha='center',\n",
        "                fontsize=12, transform=ax3.transAxes)\n",
        "\n",
        "        ax3.text(0.5, 0.3, f'Classificateur: {classifier}', ha='center',\n",
        "                fontsize=10, transform=ax3.transAxes)\n",
        "\n",
        "        # Comparaison si ensemble disponible\n",
        "        ax4 = plt.subplot(1, 4, 4)\n",
        "        if 'all_classifier_predictions' in ml_result:\n",
        "            ensemble = ml_result['all_classifier_predictions']\n",
        "\n",
        "            clf_names = list(ensemble.keys())\n",
        "            clf_confidences = [ensemble[name]['confidence'] for name in clf_names]\n",
        "            clf_predictions = [ensemble[name]['prediction'] for name in clf_names]\n",
        "\n",
        "            # Couleurs selon pr√©dictions\n",
        "            bar_colors = ['green' if pred == 'healthy' else 'orange' if pred == 'early' else 'red'\n",
        "                         for pred in clf_predictions]\n",
        "\n",
        "            bars = ax4.barh(clf_names, clf_confidences, color=bar_colors, alpha=0.7)\n",
        "            ax4.set_title('Ensemble Classifiers', fontsize=14, fontweight='bold')\n",
        "            ax4.set_xlabel('Confiance')\n",
        "            ax4.set_xlim(0, 1)\n",
        "\n",
        "            # Ajouter pr√©dictions\n",
        "            for i, (bar, pred) in enumerate(zip(bars, clf_predictions)):\n",
        "                ax4.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                        pred, va='center', fontweight='bold')\n",
        "        else:\n",
        "            ax4.axis('off')\n",
        "            ax4.text(0.5, 0.5, 'Ensemble non disponible', ha='center',\n",
        "                    transform=ax4.transAxes)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Sauvegarder\n",
        "        save_path = self.results_dir / f\"hybrid_diag_{Path(image_path).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return save_path\n",
        "\n",
        "def main_hybrid():\n",
        "    \"\"\"Programme principal syst√®me hybride\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\")\n",
        "    print(\"D√©tection YOLO + Machine Learning pour Cancer du Sein\")\n",
        "    print(\"SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Configuration seeds\n",
        "    random.seed(CONFIG['random_seed'])\n",
        "    np.random.seed(CONFIG['random_seed'])\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nMENU SYSTEME HYBRIDE\")\n",
        "        print(\"-\"*40)\n",
        "        print(\"1. Entra√Æner syst√®me hybride\")\n",
        "        print(\"2. Diagnostic hybride (image unique)\")\n",
        "        print(\"3. Diagnostic hybride (lot)\")\n",
        "        print(\"4. √âvaluation comparative\")\n",
        "        print(\"5. Analyser features importantes\")\n",
        "        print(\"6. Quitter\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        choice = input(\"Choix (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\nüîÑ ENTRAINEMENT SYSTEME HYBRIDE\")\n",
        "\n",
        "            # V√©rifier mod√®le YOLO\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Dossier images d'entra√Ænement\n",
        "            train_folder = input(\"Dossier images d'entra√Ænement: \").strip()\n",
        "            if not Path(train_folder).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "\n",
        "                # Pr√©parer donn√©es\n",
        "                X, y = hybrid_system.prepare_training_data(train_folder)\n",
        "\n",
        "                if len(X) == 0:\n",
        "                    print(\"‚ùå Aucune donn√©e d'entra√Ænement valide\")\n",
        "                    continue\n",
        "\n",
        "                # Entra√Æner\n",
        "                results = hybrid_system.train_classifiers(X, y)\n",
        "\n",
        "                print(\"\\n‚úÖ ENTRAINEMENT TERMINE!\")\n",
        "                print(f\"Mod√®les sauvegard√©s dans: {hybrid_system.classifier_dir}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nüîç DIAGNOSTIC HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            image_path = input(\"Chemin image: \").strip().strip('\"')\n",
        "            if not Path(image_path).exists():\n",
        "                print(\"‚ùå Image non trouv√©e\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "\n",
        "                # Diagnostic\n",
        "                result = hybrid_system.predict(image_path, return_probabilities=True)\n",
        "\n",
        "                # Afficher r√©sultats\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"DIAGNOSTIC HYBRIDE YOLO + ML\")\n",
        "                print(\"=\"*60)\n",
        "                print(f\"üì∏ Image: {Path(image_path).name}\")\n",
        "                print(f\"üéØ Pr√©diction: {result['prediction'].upper()}\")\n",
        "                print(f\"üìä Confiance: {result['confidence']:.2%}\")\n",
        "                print(f\"ü§ñ Classificateur: {result['classifier_used']}\")\n",
        "\n",
        "                print(\"\\nüìà Probabilit√©s d√©taill√©es:\")\n",
        "                for class_name, prob in result['probabilities'].items():\n",
        "                    print(f\"  - {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
        "\n",
        "                if 'all_classifier_predictions' in result:\n",
        "                    print(\"\\nüîÑ Pr√©dictions ensemble:\")\n",
        "                    for clf_name, clf_result in result['all_classifier_predictions'].items():\n",
        "                        print(f\"  - {clf_name}: {clf_result['prediction']} ({clf_result['confidence']:.3f})\")\n",
        "\n",
        "                # Visualisation\n",
        "                visualizer = HybridDiagnosticVisualizer()\n",
        "                save_path = visualizer.create_comprehensive_visualization(\n",
        "                    image_path, None, result\n",
        "                )\n",
        "                print(f\"\\nüìä Visualisation: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nüìÅ DIAGNOSTIC LOT HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            folder_path = input(\"Dossier images: \").strip().strip('\"')\n",
        "            if not Path(folder_path).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "                images = list(Path(folder_path).glob('*.jpg'))\n",
        "\n",
        "                if not images:\n",
        "                    print(\"‚ùå Aucune image .jpg trouv√©e\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"\\nüîÑ Traitement de {len(images)} images...\")\n",
        "\n",
        "                results_summary = defaultdict(int)\n",
        "                confidence_scores = defaultdict(list)\n",
        "                detailed_results = []\n",
        "\n",
        "                for i, img_path in enumerate(images):\n",
        "                    print(f\"  Progression: {i+1}/{len(images)} - {img_path.name}\")\n",
        "\n",
        "                    result = hybrid_system.predict(img_path)\n",
        "                    prediction = result['prediction']\n",
        "                    confidence = result['confidence']\n",
        "\n",
        "                    results_summary[prediction] += 1\n",
        "                    confidence_scores[prediction].append(confidence)\n",
        "                    detailed_results.append({\n",
        "                        'image': img_path.name,\n",
        "                        'prediction': prediction,\n",
        "                        'confidence': confidence\n",
        "                    })\n",
        "\n",
        "                # Afficher r√©sum√©\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"RESUME DIAGNOSTIC LOT HYBRIDE\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "                total = len(images)\n",
        "                for stage in ['healthy', 'early', 'advanced']:\n",
        "                    count = results_summary.get(stage, 0)\n",
        "                    avg_conf = np.mean(confidence_scores[stage]) if confidence_scores[stage] else 0\n",
        "                    percentage = (count / total) * 100\n",
        "\n",
        "                    print(f\"{stage.upper()}: {count} images ({percentage:.1f}%)\")\n",
        "                    print(f\"  Confiance moyenne: {avg_conf:.2%}\")\n",
        "\n",
        "                # Sauvegarder r√©sultats d√©taill√©s\n",
        "                df = pd.DataFrame(detailed_results)\n",
        "                results_file = Path(CONFIG['results_dir']) / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "                df.to_csv(results_file, index=False)\n",
        "                print(f\"\\nüìÑ R√©sultats d√©taill√©s: {results_file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\nüìä EVALUATION COMPARATIVE\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez comparer performances syst√®me hybride vs r√®gles expertes\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"\\nüéØ ANALYSE FEATURES IMPORTANTES\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez analyser quelles features sont les plus importantes\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(\"\\nüëã Au revoir! Merci d'avoir utilis√© le syst√®me hybride!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main_hybrid()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n‚ö†Ô∏è Interruption utilisateur\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERREUR CRITIQUE: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "\n",
        "# Configuration syst√®me optimis√©e\n",
        "CONFIG = {\n",
        "    'base_dir': '.',\n",
        "    'output_dir': 'mtc_output',\n",
        "    'model_dir': 'mtc_models',\n",
        "    'results_dir': 'mtc_results',\n",
        "    'classifier_dir': 'mtc_classifiers',\n",
        "    'train_split': 0.8,\n",
        "    'epochs': 200,\n",
        "    'batch_size': 16,\n",
        "    'imgsz': 640,\n",
        "    'patience': 50,\n",
        "    'conf_threshold': 0.15,\n",
        "    'iou_threshold': 0.3,\n",
        "    'augmentation_factor': 8,\n",
        "    'target_accuracy': 0.85,\n",
        "    'random_seed': 42,\n",
        "    'lr0': 0.0008,\n",
        "    'weight_decay': 0.001,\n",
        "    'mosaic': 0.8,\n",
        "    'mixup': 0.1,\n",
        "    'copy_paste': 0.1,\n",
        "}\n",
        "\n",
        "# Classes YOLO (16 classes)\n",
        "CLASS_NAMES = [\n",
        "    'Ecchymoses', 'Eduit_jaune_epais', 'Eduit_jaune_mince', 'Fissure',\n",
        "    'Langue_normal', 'Langue_pale', 'Langue_petite', 'Langue_rose',\n",
        "    'Langue_rouge', 'Langue_rouge_foncee', 'enduit_blanc_epais',\n",
        "    'enduit_blanc_mince', 'langue_ganfelee', 'red_dot',\n",
        "    'salive_humide', 'salive_normale'\n",
        "]\n",
        "\n",
        "# Zones MTC\n",
        "TONGUE_ZONES = {\n",
        "    'kidney': {\n",
        "        'name': 'Rein',\n",
        "        'coords': [(0.2, 0), (0.8, 0), (0.8, 0.15), (0.2, 0.15)],\n",
        "        'color': (75, 0, 130)\n",
        "    },\n",
        "    'liver_gall_right': {\n",
        "        'name': 'Foie-VB Droit',\n",
        "        'coords': [(0, 0.15), (0.3, 0.15), (0.3, 0.65), (0, 0.65)],\n",
        "        'color': (34, 139, 34)\n",
        "    },\n",
        "    'liver_gall_left': {\n",
        "        'name': 'Foie-VB Gauche',\n",
        "        'coords': [(0.7, 0.15), (1, 0.15), (1, 0.65), (0.7, 0.65)],\n",
        "        'color': (50, 205, 50)\n",
        "    },\n",
        "    'spleen_stomach': {\n",
        "        'name': 'Rate-Estomac',\n",
        "        'coords': [(0.3, 0.15), (0.7, 0.15), (0.7, 0.65), (0.3, 0.65)],\n",
        "        'color': (255, 215, 0)\n",
        "    },\n",
        "    'heart_lung': {\n",
        "        'name': 'Coeur-Poumon',\n",
        "        'coords': [(0.2, 0.65), (0.8, 0.65), (0.8, 1), (0.2, 1)],\n",
        "        'color': (220, 20, 60)\n",
        "    }\n",
        "}\n",
        "\n",
        "class YOLOFeatureExtractor:\n",
        "    \"\"\"Extracteur de features bas√© sur les d√©tections YOLO\"\"\"\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "        except ImportError:\n",
        "            print(\"Installation d'ultralytics...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ultralytics'])\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "\n",
        "        # Stocker derni√®res d√©tections pour visualisation\n",
        "        self.last_detections = []\n",
        "\n",
        "    def extract_features(self, image_path, return_detections=False):\n",
        "        \"\"\"Extrait features compl√®tes d'une image\"\"\"\n",
        "        try:\n",
        "            results = self.model(image_path, conf=CONFIG['conf_threshold'],\n",
        "                               iou=CONFIG['iou_threshold'], verbose=False)\n",
        "\n",
        "            image = cv2.imread(str(image_path))\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # Initialiser features\n",
        "            features = self._initialize_features()\n",
        "\n",
        "            # Traiter d√©tections\n",
        "            detections = []\n",
        "            for r in results:\n",
        "                if r.boxes is not None:\n",
        "                    for box in r.boxes:\n",
        "                        bbox = box.xyxy[0].cpu().numpy()\n",
        "                        conf = float(box.conf)\n",
        "                        cls = int(box.cls)\n",
        "\n",
        "                        if cls < len(CLASS_NAMES):\n",
        "                            detection = {\n",
        "                                'bbox': bbox,\n",
        "                                'confidence': conf,\n",
        "                                'class': cls,\n",
        "                                'class_name': CLASS_NAMES[cls]\n",
        "                            }\n",
        "                            detections.append(detection)\n",
        "\n",
        "            # Stocker d√©tections pour visualisation\n",
        "            self.last_detections = detections\n",
        "\n",
        "            # Extraire features des d√©tections\n",
        "            features = self._extract_detection_features(detections, features, w, h)\n",
        "            features = self._extract_spatial_features(detections, features, w, h)\n",
        "            features = self._extract_statistical_features(detections, features)\n",
        "            features = self._extract_zone_features(detections, features, w, h)\n",
        "\n",
        "            if return_detections:\n",
        "                return np.array(list(features.values())), detections\n",
        "            else:\n",
        "                return np.array(list(features.values()))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur extraction features: {e}\")\n",
        "            if return_detections:\n",
        "                return np.zeros(self._get_feature_count()), []\n",
        "            else:\n",
        "                return np.zeros(self._get_feature_count())\n",
        "\n",
        "    def get_last_detections(self):\n",
        "        \"\"\"Retourne derni√®res d√©tections YOLO\"\"\"\n",
        "        return self.last_detections\n",
        "\n",
        "    def _initialize_features(self):\n",
        "        \"\"\"Initialise toutes les features √† 0\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Features par classe (confidence max et count)\n",
        "        for class_name in CLASS_NAMES:\n",
        "            features[f'{class_name}_max_conf'] = 0.0\n",
        "            features[f'{class_name}_count'] = 0.0\n",
        "            features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        # Features spatiales\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            features[f'{zone}_detection_count'] = 0.0\n",
        "            features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        # Features statistiques globales\n",
        "        features['total_detections'] = 0.0\n",
        "        features['avg_confidence_all'] = 0.0\n",
        "        features['std_confidence'] = 0.0\n",
        "        features['detection_density'] = 0.0\n",
        "\n",
        "        # Features morphologiques\n",
        "        features['tongue_area_ratio'] = 0.0\n",
        "        features['detection_spread_x'] = 0.0\n",
        "        features['detection_spread_y'] = 0.0\n",
        "\n",
        "        # Features de co-occurrence\n",
        "        features['pathological_combinations'] = 0.0\n",
        "        features['healthy_indicators'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_detection_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features bas√©es sur les d√©tections\"\"\"\n",
        "        class_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            class_name = det['class_name']\n",
        "            conf = det['confidence']\n",
        "            class_detections[class_name].append(conf)\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            confs = class_detections[class_name]\n",
        "            if confs:\n",
        "                features[f'{class_name}_max_conf'] = max(confs)\n",
        "                features[f'{class_name}_count'] = len(confs)\n",
        "                features[f'{class_name}_avg_conf'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{class_name}_max_conf'] = 0.0\n",
        "                features[f'{class_name}_count'] = 0.0\n",
        "                features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_spatial_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features spatiales et de zones\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        # Calculer centroids normalis√©s\n",
        "        centroids = []\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "            centroids.append((cx, cy))\n",
        "\n",
        "        # Spread spatial\n",
        "        if centroids:\n",
        "            x_coords = [c[0] for c in centroids]\n",
        "            y_coords = [c[1] for c in centroids]\n",
        "            features['detection_spread_x'] = np.std(x_coords) if len(x_coords) > 1 else 0\n",
        "            features['detection_spread_y'] = np.std(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_statistical_features(self, detections, features):\n",
        "        \"\"\"Extrait features statistiques globales\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        confidences = [det['confidence'] for det in detections]\n",
        "\n",
        "        features['total_detections'] = len(detections)\n",
        "        features['avg_confidence_all'] = np.mean(confidences)\n",
        "        features['std_confidence'] = np.std(confidences)\n",
        "        features['detection_density'] = len(detections) / 100.0  # Normalis√©\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_zone_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features par zone MTC\"\"\"\n",
        "        zone_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "\n",
        "            zone = self._find_zone(cx, cy)\n",
        "            if zone:\n",
        "                zone_detections[zone].append(det['confidence'])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            confs = zone_detections[zone]\n",
        "            if confs:\n",
        "                features[f'{zone}_detection_count'] = len(confs)\n",
        "                features[f'{zone}_avg_confidence'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{zone}_detection_count'] = 0.0\n",
        "                features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _find_zone(self, x, y):\n",
        "        \"\"\"Trouve zone pour coordonn√©es\"\"\"\n",
        "        for zone_name, zone_info in TONGUE_ZONES.items():\n",
        "            if self._point_in_polygon(x, y, zone_info['coords']):\n",
        "                return zone_name\n",
        "        return None\n",
        "\n",
        "    def _point_in_polygon(self, x, y, coords):\n",
        "        \"\"\"Test point dans polygone\"\"\"\n",
        "        n = len(coords)\n",
        "        inside = False\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            xi, yi = coords[i]\n",
        "            xj, yj = coords[j]\n",
        "            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "    def _get_feature_count(self):\n",
        "        \"\"\"Retourne le nombre total de features\"\"\"\n",
        "        # 3 features par classe (48) + 10 zones x 2 (20) + 7 globales + 2 morpho + 2 co-occur\n",
        "        return len(CLASS_NAMES) * 3 + len(TONGUE_ZONES) * 2 + 7 + 2 + 2\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        \"\"\"Retourne noms des features\"\"\"\n",
        "        names = []\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            names.extend([\n",
        "                f'{class_name}_max_conf',\n",
        "                f'{class_name}_count',\n",
        "                f'{class_name}_avg_conf'\n",
        "            ])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            names.extend([\n",
        "                f'{zone}_detection_count',\n",
        "                f'{zone}_avg_confidence'\n",
        "            ])\n",
        "\n",
        "        # Features globales\n",
        "        names.extend([\n",
        "            'total_detections', 'avg_confidence_all', 'std_confidence',\n",
        "            'detection_density', 'tongue_area_ratio', 'detection_spread_x',\n",
        "            'detection_spread_y', 'pathological_combinations', 'healthy_indicators'\n",
        "        ])\n",
        "\n",
        "        return names\n",
        "\n",
        "class HybridClassificationSystem:\n",
        "    \"\"\"Syst√®me hybride YOLO + Classification ML\"\"\"\n",
        "\n",
        "    def __init__(self, yolo_model_path):\n",
        "        self.feature_extractor = YOLOFeatureExtractor(yolo_model_path)\n",
        "        self.classifiers = {}\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.is_trained = False\n",
        "\n",
        "        # Cr√©er dossier pour sauvegardes\n",
        "        self.classifier_dir = Path(CONFIG['classifier_dir'])\n",
        "        self.classifier_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def prepare_training_data(self, image_folder, labels_file=None):\n",
        "        \"\"\"Pr√©pare donn√©es d'entra√Ænement\"\"\"\n",
        "        print(\"PREPARATION DES DONNEES D'ENTRAINEMENT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "\n",
        "        # Collecter images et labels\n",
        "        for img_path in Path(image_folder).glob('*.jpg'):\n",
        "            image_paths.append(img_path)\n",
        "\n",
        "            # Extraire label du nom de fichier (comme dans votre code original)\n",
        "            label = self._extract_label_from_filename(img_path.name)\n",
        "            labels.append(label)\n",
        "\n",
        "        print(f\"Images trouv√©es: {len(image_paths)}\")\n",
        "\n",
        "        # Distribution des labels\n",
        "        label_counts = defaultdict(int)\n",
        "        for label in labels:\n",
        "            label_counts[label] += 1\n",
        "\n",
        "        print(\"Distribution des labels:\")\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"  - {label}: {count}\")\n",
        "\n",
        "        # Extraire features\n",
        "        print(\"\\nExtraction des features...\")\n",
        "        features_list = []\n",
        "        valid_labels = []\n",
        "\n",
        "        for i, (img_path, label) in enumerate(zip(image_paths, labels)):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"  Progression: {i}/{len(image_paths)}\")\n",
        "\n",
        "            features = self.feature_extractor.extract_features(img_path)\n",
        "            if features is not None and not np.all(features == 0):\n",
        "                features_list.append(features)\n",
        "                valid_labels.append(label)\n",
        "\n",
        "        X = np.array(features_list)\n",
        "        y = np.array(valid_labels)\n",
        "\n",
        "        print(f\"\\nFeatures extraites: {X.shape}\")\n",
        "        print(f\"Features par image: {X.shape[1]}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train_classifiers(self, X, y):\n",
        "        \"\"\"Entra√Æne plusieurs classificateurs\"\"\"\n",
        "        print(\"\\nENTRAINEMENT DES CLASSIFICATEURS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Encoder labels\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "\n",
        "        # Split train/test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=CONFIG['random_seed'],\n",
        "            stratify=y_encoded\n",
        "        )\n",
        "\n",
        "        # Normaliser features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # D√©finir classificateurs\n",
        "        classifiers_config = {\n",
        "            'RandomForest': {\n",
        "                'model': RandomForestClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=15,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model': xgb.XGBClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'SVM': {\n",
        "                'model': SVC(\n",
        "                    kernel='rbf',\n",
        "                    C=10,\n",
        "                    gamma='scale',\n",
        "                    probability=True,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'MLP': {\n",
        "                'model': MLPClassifier(\n",
        "                    hidden_layer_sizes=(128, 64, 32),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.001,\n",
        "                    learning_rate='adaptive',\n",
        "                    max_iter=500,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'GradientBoosting': {\n",
        "                'model': GradientBoostingClassifier(\n",
        "                    n_estimators=200,\n",
        "                    learning_rate=0.1,\n",
        "                    max_depth=8,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Entra√Æner et √©valuer chaque classificateur\n",
        "        results = {}\n",
        "\n",
        "        for name, config in classifiers_config.items():\n",
        "            print(f\"\\nEntra√Ænement {name}...\")\n",
        "\n",
        "            model = config['model']\n",
        "\n",
        "            if config['use_scaling']:\n",
        "                X_train_input = X_train_scaled\n",
        "                X_test_input = X_test_scaled\n",
        "            else:\n",
        "                X_train_input = X_train\n",
        "                X_test_input = X_test\n",
        "\n",
        "            # Entra√Æner\n",
        "            model.fit(X_train_input, y_train)\n",
        "\n",
        "            # Pr√©dictions\n",
        "            y_pred = model.predict(X_test_input)\n",
        "            y_pred_proba = model.predict_proba(X_test_input)\n",
        "\n",
        "            # M√©triques\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            # Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_input, y_train, cv=5)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'accuracy': accuracy,\n",
        "                'cv_mean': cv_scores.mean(),\n",
        "                'cv_std': cv_scores.std(),\n",
        "                'use_scaling': config['use_scaling']\n",
        "            }\n",
        "\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "            # Rapport d√©taill√© pour le meilleur mod√®le\n",
        "            if name == 'RandomForest':  # Afficher d√©tails pour RF\n",
        "                print(f\"\\nRapport d√©taill√© {name}:\")\n",
        "                class_names = self.label_encoder.classes_\n",
        "                print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "        # S√©lectionner meilleur mod√®le\n",
        "        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
        "        best_model_info = results[best_name]\n",
        "\n",
        "        print(f\"\\nüèÜ MEILLEUR MODELE: {best_name}\")\n",
        "        print(f\"   Accuracy: {best_model_info['accuracy']:.4f}\")\n",
        "        print(f\"   CV Score: {best_model_info['cv_mean']:.4f}\")\n",
        "\n",
        "        # Sauvegarder mod√®les\n",
        "        self.classifiers = results\n",
        "        self.best_classifier_name = best_name\n",
        "        self.is_trained = True\n",
        "\n",
        "        # Sauvegarder sur disque\n",
        "        self.save_models()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict(self, image_path, return_probabilities=False):\n",
        "        \"\"\"Pr√©diction hybride YOLO + Classification\"\"\"\n",
        "        if not self.is_trained:\n",
        "            self.load_models()\n",
        "\n",
        "        # Extraire features avec YOLO et r√©cup√©rer d√©tections\n",
        "        features, detections = self.feature_extractor.extract_features(image_path, return_detections=True)\n",
        "\n",
        "        if features is None or np.all(features == 0):\n",
        "            return {\n",
        "                'prediction': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'probabilities': {},\n",
        "                'detections': [],\n",
        "                'detected_features': {},\n",
        "                'error': 'Aucune feature extraite'\n",
        "            }\n",
        "\n",
        "        # Utiliser le meilleur classificateur\n",
        "        best_clf_info = self.classifiers[self.best_classifier_name]\n",
        "        model = best_clf_info['model']\n",
        "        use_scaling = best_clf_info['use_scaling']\n",
        "\n",
        "        # Pr√©parer features\n",
        "        features_reshaped = features.reshape(1, -1)\n",
        "        if use_scaling:\n",
        "            features_reshaped = self.scaler.transform(features_reshaped)\n",
        "\n",
        "        # Pr√©diction\n",
        "        prediction_encoded = model.predict(features_reshaped)[0]\n",
        "        prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "\n",
        "        # Probabilit√©s\n",
        "        probabilities = model.predict_proba(features_reshaped)[0]\n",
        "        prob_dict = {}\n",
        "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
        "            prob_dict[class_name] = probabilities[i]\n",
        "\n",
        "        confidence = max(probabilities)\n",
        "\n",
        "        # Extraire features significatives pour affichage\n",
        "        feature_names = self.feature_extractor.get_feature_names()\n",
        "        detected_features = {}\n",
        "        for i, (name, value) in enumerate(zip(feature_names, features)):\n",
        "            if value > 0 and 'count' not in name.lower():  # Exclure les counts pour lisibilit√©\n",
        "                detected_features[name] = value\n",
        "\n",
        "        # Trier par importance\n",
        "        detected_features = dict(sorted(detected_features.items(),\n",
        "                                      key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        result = {\n",
        "            'prediction': prediction,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': prob_dict,\n",
        "            'classifier_used': self.best_classifier_name,\n",
        "            'detections': detections,\n",
        "            'detected_features': detected_features\n",
        "        }\n",
        "\n",
        "        if return_probabilities:\n",
        "            result['all_classifier_predictions'] = self._get_ensemble_predictions(features_reshaped)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _get_ensemble_predictions(self, features):\n",
        "        \"\"\"Pr√©dictions ensemble de tous les classificateurs\"\"\"\n",
        "        ensemble_results = {}\n",
        "\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model = clf_info['model']\n",
        "            use_scaling = clf_info['use_scaling']\n",
        "\n",
        "            features_input = self.scaler.transform(features) if use_scaling else features\n",
        "\n",
        "            prediction_encoded = model.predict(features_input)[0]\n",
        "            prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "            probabilities = model.predict_proba(features_input)[0]\n",
        "\n",
        "            ensemble_results[name] = {\n",
        "                'prediction': prediction,\n",
        "                'confidence': max(probabilities),\n",
        "                'probabilities': dict(zip(self.label_encoder.classes_, probabilities))\n",
        "            }\n",
        "\n",
        "        return ensemble_results\n",
        "\n",
        "    def save_models(self):\n",
        "        \"\"\"Sauvegarde mod√®les et preprocessing\"\"\"\n",
        "        print(f\"\\nSauvegarde mod√®les dans {self.classifier_dir}\")\n",
        "\n",
        "        # Sauvegarder chaque classificateur\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            joblib.dump(clf_info['model'], model_path)\n",
        "\n",
        "        # Sauvegarder preprocessing\n",
        "        joblib.dump(self.scaler, self.classifier_dir / \"scaler.joblib\")\n",
        "        joblib.dump(self.label_encoder, self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Sauvegarder config\n",
        "        config = {\n",
        "            'best_classifier': self.best_classifier_name,\n",
        "            'classifiers_config': {name: {'use_scaling': info['use_scaling']}\n",
        "                                 for name, info in self.classifiers.items()},\n",
        "            'feature_names': self.feature_extractor.get_feature_names()\n",
        "        }\n",
        "\n",
        "        with open(self.classifier_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"‚úÖ Mod√®les sauvegard√©s\")\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Charge mod√®les sauvegard√©s\"\"\"\n",
        "        config_path = self.classifier_dir / \"config.json\"\n",
        "\n",
        "        if not config_path.exists():\n",
        "            raise FileNotFoundError(\"Aucun mod√®le sauvegard√© trouv√©\")\n",
        "\n",
        "        print(\"Chargement mod√®les sauvegard√©s...\")\n",
        "\n",
        "        # Charger config\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        self.best_classifier_name = config['best_classifier']\n",
        "\n",
        "        # Charger preprocessing\n",
        "        self.scaler = joblib.load(self.classifier_dir / \"scaler.joblib\")\n",
        "        self.label_encoder = joblib.load(self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Charger classificateurs\n",
        "        self.classifiers = {}\n",
        "        for name, clf_config in config['classifiers_config'].items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            if model_path.exists():\n",
        "                model = joblib.load(model_path)\n",
        "                self.classifiers[name] = {\n",
        "                    'model': model,\n",
        "                    'use_scaling': clf_config['use_scaling']\n",
        "                }\n",
        "\n",
        "        self.is_trained = True\n",
        "        print(\"‚úÖ Mod√®les charg√©s\")\n",
        "\n",
        "    def _extract_label_from_filename(self, filename):\n",
        "        \"\"\"Extrait label du nom de fichier\"\"\"\n",
        "        filename_lower = filename.lower()\n",
        "\n",
        "        if any(keyword in filename_lower for keyword in ['healthy', 'sain', 'normal']):\n",
        "            return 'healthy'\n",
        "        elif any(keyword in filename_lower for keyword in ['ebc', 'early', 'precoce']):\n",
        "            return 'early'\n",
        "        elif any(keyword in filename_lower for keyword in ['abc', 'advanced', 'avance']):\n",
        "            return 'advanced'\n",
        "        elif any(keyword in filename_lower for keyword in ['real']):\n",
        "            if any(keyword in filename_lower for keyword in ['1', 'one', 'first']):\n",
        "                return 'healthy'\n",
        "            elif any(keyword in filename_lower for keyword in ['2', 'two', 'second']):\n",
        "                return 'early'\n",
        "            elif any(keyword in filename_lower for keyword in ['3', 'three', 'third']):\n",
        "                return 'advanced'\n",
        "            else:\n",
        "                return 'unknown'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "class HybridDiagnosticVisualizer:\n",
        "    \"\"\"Visualiseur pour syst√®me hybride avec cartographie MTC\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results_dir = Path(CONFIG['results_dir'])\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "        self.zones = TONGUE_ZONES\n",
        "\n",
        "    def create_comprehensive_visualization(self, image_path, yolo_detections, ml_result, feature_extractor=None):\n",
        "        \"\"\"Cr√©e visualisation compl√®te avec cartographie MTC\"\"\"\n",
        "        image = cv2.imread(str(image_path))\n",
        "\n",
        "        # R√©cup√©rer les d√©tections YOLO brutes si n√©cessaire\n",
        "        if yolo_detections is None:\n",
        "            yolo_detections = self._get_yolo_detections(image_path, feature_extractor)\n",
        "\n",
        "        fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "        # 1. Image avec d√©tections YOLO et bounding boxes\n",
        "        ax1 = plt.subplot(1, 3, 1)\n",
        "        ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        ax1.set_title('D√©tections YOLO', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Ajouter bounding boxes avec labels\n",
        "        for det in yolo_detections:\n",
        "            bbox = det['bbox']\n",
        "            x1, y1, x2, y2 = bbox\n",
        "\n",
        "            color = self._get_color_for_class(det['class_name'])\n",
        "\n",
        "            # Rectangle de d√©tection\n",
        "            rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                           linewidth=2, edgecolor=color, facecolor='none')\n",
        "            ax1.add_patch(rect)\n",
        "\n",
        "            # Label avec confiance\n",
        "            label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
        "            ax1.text(x1, y1-5, label, color='white', backgroundcolor=color,\n",
        "                    fontsize=8, weight='bold')\n",
        "\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # 2. Cartographie MTC avec zones et d√©tections\n",
        "        ax2 = plt.subplot(1, 3, 2)\n",
        "        ax2.set_xlim(0, 1)\n",
        "        ax2.set_ylim(1, 0)  # Inverser Y pour correspondre √† l'image\n",
        "        ax2.set_aspect('equal')\n",
        "        ax2.set_title('Cartographie MTC', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Dessiner zones MTC\n",
        "        zone_counts = defaultdict(int)\n",
        "        for zone_name, zone_info in self.zones.items():\n",
        "            coords = zone_info['coords']\n",
        "            color = np.array(zone_info['color']) / 255.0\n",
        "\n",
        "            # Polygone de zone\n",
        "            polygon = Polygon(coords, facecolor=color, alpha=0.3,\n",
        "                            edgecolor='black', linewidth=2)\n",
        "            ax2.add_patch(polygon)\n",
        "\n",
        "            # Nom de zone au centre\n",
        "            cx = np.mean([c[0] for c in coords])\n",
        "            cy = np.mean([c[1] for c in coords])\n",
        "            ax2.text(cx, cy, zone_info['name'], ha='center', va='center',\n",
        "                    fontsize=11, weight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
        "\n",
        "        # Projeter d√©tections sur cartographie\n",
        "        h, w = image.shape[:2]\n",
        "        for det in yolo_detections:\n",
        "            bbox = det['bbox']\n",
        "            # Calculer centre de la d√©tection\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "\n",
        "            # Trouver zone correspondante\n",
        "            zone = self._find_zone(cx, cy)\n",
        "            if zone:\n",
        "                zone_counts[zone] += 1\n",
        "\n",
        "            # Afficher d√©tection sur cartographie\n",
        "            color = self._get_color_for_class(det['class_name'])\n",
        "            ax2.scatter(cx, cy, s=150, c=color, marker='x', linewidths=4, alpha=0.8)\n",
        "\n",
        "            # Ajouter label pr√®s du point\n",
        "            ax2.text(cx+0.02, cy, det['class_name'][:8], fontsize=8,\n",
        "                    color=color, weight='bold')\n",
        "\n",
        "        ax2.set_xlabel('Gauche ‚Üê ‚Üí Droite', fontsize=10)\n",
        "        ax2.set_ylabel('Avant ‚Üê ‚Üí Arri√®re', fontsize=10)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Diagnostic final avec d√©tails\n",
        "        ax3 = plt.subplot(1, 3, 3)\n",
        "        ax3.axis('off')\n",
        "\n",
        "        prediction = ml_result['prediction']\n",
        "        confidence = ml_result['confidence']\n",
        "        classifier = ml_result['classifier_used']\n",
        "\n",
        "        # Couleurs et messages selon diagnostic\n",
        "        if prediction == 'healthy':\n",
        "            color = 'green'\n",
        "            message = \"LANGUE SAINE\\nAucun signe pathologique\"\n",
        "        elif prediction == 'early':\n",
        "            color = 'orange'\n",
        "            message = \"STADE PRECOCE (EBC)\\nSignes initiaux d√©tect√©s\"\n",
        "        else:\n",
        "            color = 'red'\n",
        "            message = \"STADE AVANCE (ABC)\\nSignes pathologiques importants\"\n",
        "\n",
        "        # Titre diagnostic\n",
        "        ax3.text(0.5, 0.95, 'DIAGNOSTIC MTC HYBRIDE', ha='center', fontsize=16,\n",
        "                weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        # R√©sultat principal\n",
        "        ax3.text(0.5, 0.85, message, ha='center', fontsize=12,\n",
        "                color=color, weight='bold', transform=ax3.transAxes,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=color, alpha=0.1))\n",
        "\n",
        "        # Confiance\n",
        "        ax3.text(0.5, 0.70, f'Confiance: {confidence:.1%}', ha='center',\n",
        "                fontsize=12, weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        # Classificateur utilis√©\n",
        "        ax3.text(0.5, 0.62, f'Classificateur: {classifier}', ha='center',\n",
        "                fontsize=10, style='italic', transform=ax3.transAxes)\n",
        "\n",
        "        # Scores d√©taill√©s\n",
        "        y_pos = 0.52\n",
        "        ax3.text(0.1, y_pos, 'Scores d√©taill√©s:', fontsize=11, weight='bold',\n",
        "                transform=ax3.transAxes)\n",
        "\n",
        "        for stage, prob in ml_result['probabilities'].items():\n",
        "            y_pos -= 0.06\n",
        "            stage_color = 'green' if stage == 'healthy' else 'orange' if stage == 'early' else 'red'\n",
        "            ax3.text(0.15, y_pos, f'{stage}: {prob:.1%}', fontsize=10,\n",
        "                    color=stage_color, transform=ax3.transAxes)\n",
        "\n",
        "        # Localisation par zones\n",
        "        if zone_counts:\n",
        "            y_pos -= 0.08\n",
        "            ax3.text(0.1, y_pos, 'Localisation MTC:', fontsize=11, weight='bold',\n",
        "                    transform=ax3.transAxes)\n",
        "\n",
        "            for zone, count in zone_counts.items():\n",
        "                if count > 0:\n",
        "                    y_pos -= 0.05\n",
        "                    zone_name = self.zones[zone]['name']\n",
        "                    ax3.text(0.15, y_pos, f'{zone_name}: {count}', fontsize=9,\n",
        "                            transform=ax3.transAxes)\n",
        "\n",
        "        # Caract√©ristiques d√©tect√©es\n",
        "        if 'detected_features' in ml_result:\n",
        "            y_pos -= 0.08\n",
        "            ax3.text(0.1, y_pos, 'Caract√©ristiques:', fontsize=11, weight='bold',\n",
        "                    transform=ax3.transAxes)\n",
        "\n",
        "            features = ml_result['detected_features']\n",
        "            for feature, score in list(features.items())[:5]:  # Top 5\n",
        "                if score > 0:\n",
        "                    y_pos -= 0.04\n",
        "                    ax3.text(0.15, y_pos, f'{feature}: {score:.2f}', fontsize=8,\n",
        "                            transform=ax3.transAxes)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Sauvegarder\n",
        "        save_path = self.results_dir / f\"hybrid_mtc_{Path(image_path).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return save_path, zone_counts\n",
        "\n",
        "    def _get_yolo_detections(self, image_path, feature_extractor=None):\n",
        "        \"\"\"R√©cup√®re d√©tections YOLO brutes si pas fournies\"\"\"\n",
        "        if feature_extractor:\n",
        "            _, detections = feature_extractor.extract_features(image_path, return_detections=True)\n",
        "            return detections\n",
        "        else:\n",
        "            # Fallback : essayer de cr√©er un extracteur temporaire\n",
        "            try:\n",
        "                from ultralytics import YOLO\n",
        "                model = YOLO('yolov8s.pt')  # Mod√®le par d√©faut\n",
        "                results = model(image_path, conf=CONFIG['conf_threshold'], verbose=False)\n",
        "\n",
        "                detections = []\n",
        "                for r in results:\n",
        "                    if r.boxes is not None:\n",
        "                        for box in r.boxes:\n",
        "                            bbox = box.xyxy[0].cpu().numpy()\n",
        "                            conf = float(box.conf)\n",
        "                            cls = int(box.cls)\n",
        "\n",
        "                            if cls < len(CLASS_NAMES):\n",
        "                                detection = {\n",
        "                                    'bbox': bbox,\n",
        "                                    'confidence': conf,\n",
        "                                    'class': cls,\n",
        "                                    'class_name': CLASS_NAMES[cls]\n",
        "                                }\n",
        "                                detections.append(detection)\n",
        "                return detections\n",
        "            except:\n",
        "                return []\n",
        "\n",
        "    def _get_color_for_class(self, class_name):\n",
        "        \"\"\"Retourne couleur selon classe (m√™me logique que votre code original)\"\"\"\n",
        "        if any(x in class_name for x in ['normal', 'rose', 'salive_normale']):\n",
        "            return 'green'\n",
        "        elif any(x in class_name for x in ['pale', 'blanc_mince', 'jaune_mince']):\n",
        "            return 'orange'\n",
        "        elif any(x in class_name for x in ['rouge_foncee', 'jaune_epais', 'Ecchymoses']):\n",
        "            return 'red'\n",
        "        elif any(x in class_name for x in ['rouge', 'blanc_epais']):\n",
        "            return 'darkorange'\n",
        "        elif 'red_dot' in class_name:\n",
        "            return 'crimson'\n",
        "        elif 'Fissure' in class_name:\n",
        "            return 'purple'\n",
        "        else:\n",
        "            return 'gray'\n",
        "\n",
        "    def _find_zone(self, x, y):\n",
        "        \"\"\"Trouve zone MTC pour coordonn√©es (m√™me logique que votre code)\"\"\"\n",
        "        for zone_name, zone_info in self.zones.items():\n",
        "            if self._point_in_polygon(x, y, zone_info['coords']):\n",
        "                return zone_name\n",
        "        return None\n",
        "\n",
        "    def _point_in_polygon(self, x, y, coords):\n",
        "        \"\"\"Test point dans polygone (m√™me algorithme que votre code)\"\"\"\n",
        "        n = len(coords)\n",
        "        inside = False\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            xi, yi = coords[i]\n",
        "            xj, yj = coords[j]\n",
        "            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "def main_hybrid():\n",
        "    \"\"\"Programme principal syst√®me hybride\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\")\n",
        "    print(\"D√©tection YOLO + Machine Learning pour Cancer du Sein\")\n",
        "    print(\"SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Configuration seeds\n",
        "    random.seed(CONFIG['random_seed'])\n",
        "    np.random.seed(CONFIG['random_seed'])\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nMENU SYSTEME HYBRIDE\")\n",
        "        print(\"-\"*40)\n",
        "        print(\"1. Entra√Æner syst√®me hybride\")\n",
        "        print(\"2. Diagnostic hybride (image unique)\")\n",
        "        print(\"3. Diagnostic hybride (lot)\")\n",
        "        print(\"4. √âvaluation comparative\")\n",
        "        print(\"5. Analyser features importantes\")\n",
        "        print(\"6. Quitter\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        choice = input(\"Choix (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\nüîÑ ENTRAINEMENT SYSTEME HYBRIDE\")\n",
        "\n",
        "            # V√©rifier mod√®le YOLO\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Dossier images d'entra√Ænement\n",
        "            train_folder = input(\"Dossier images d'entra√Ænement: \").strip()\n",
        "            if not Path(train_folder).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "\n",
        "                # Pr√©parer donn√©es\n",
        "                X, y = hybrid_system.prepare_training_data(train_folder)\n",
        "\n",
        "                if len(X) == 0:\n",
        "                    print(\"‚ùå Aucune donn√©e d'entra√Ænement valide\")\n",
        "                    continue\n",
        "\n",
        "                # Entra√Æner\n",
        "                results = hybrid_system.train_classifiers(X, y)\n",
        "\n",
        "                print(\"\\n‚úÖ ENTRAINEMENT TERMINE!\")\n",
        "                print(f\"Mod√®les sauvegard√©s dans: {hybrid_system.classifier_dir}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nüîç DIAGNOSTIC HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            image_path = input(\"Chemin image: \").strip().strip('\"')\n",
        "            if not Path(image_path).exists():\n",
        "                print(\"‚ùå Image non trouv√©e\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "\n",
        "                # Diagnostic\n",
        "                result = hybrid_system.predict(image_path, return_probabilities=True)\n",
        "\n",
        "                # Afficher r√©sultats\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"DIAGNOSTIC HYBRIDE YOLO + ML\")\n",
        "                print(\"=\"*60)\n",
        "                print(f\"üì∏ Image: {Path(image_path).name}\")\n",
        "                print(f\"üéØ Pr√©diction: {result['prediction'].upper()}\")\n",
        "                print(f\"üìä Confiance: {result['confidence']:.2%}\")\n",
        "                print(f\"ü§ñ Classificateur: {result['classifier_used']}\")\n",
        "\n",
        "                print(\"\\nüìà Probabilit√©s d√©taill√©es:\")\n",
        "                for class_name, prob in result['probabilities'].items():\n",
        "                    print(f\"  - {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
        "\n",
        "                if 'all_classifier_predictions' in result:\n",
        "                    print(\"\\nüîÑ Pr√©dictions ensemble:\")\n",
        "                    for clf_name, clf_result in result['all_classifier_predictions'].items():\n",
        "                        print(f\"  - {clf_name}: {clf_result['prediction']} ({clf_result['confidence']:.3f})\")\n",
        "\n",
        "                # Visualisation avec cartographie MTC\n",
        "                visualizer = HybridDiagnosticVisualizer()\n",
        "                save_path, zone_counts = visualizer.create_comprehensive_visualization(\n",
        "                    image_path, result['detections'], result, hybrid_system.feature_extractor\n",
        "                )\n",
        "\n",
        "                # Afficher informations zones\n",
        "                if zone_counts:\n",
        "                    print(\"\\nüó∫Ô∏è Localisation par zones MTC:\")\n",
        "                    for zone, count in zone_counts.items():\n",
        "                        if count > 0:\n",
        "                            zone_name = TONGUE_ZONES[zone]['name']\n",
        "                            print(f\"  - {zone_name}: {count} d√©tection(s)\")\n",
        "\n",
        "                print(f\"\\nüìä Visualisation compl√®te: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nüìÅ DIAGNOSTIC LOT HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            folder_path = input(\"Dossier images: \").strip().strip('\"')\n",
        "            if not Path(folder_path).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model)\n",
        "                images = list(Path(folder_path).glob('*.jpg'))\n",
        "\n",
        "                if not images:\n",
        "                    print(\"‚ùå Aucune image .jpg trouv√©e\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"\\nüîÑ Traitement de {len(images)} images...\")\n",
        "\n",
        "                results_summary = defaultdict(int)\n",
        "                confidence_scores = defaultdict(list)\n",
        "                detailed_results = []\n",
        "\n",
        "                for i, img_path in enumerate(images):\n",
        "                    print(f\"  Progression: {i+1}/{len(images)} - {img_path.name}\")\n",
        "\n",
        "                    result = hybrid_system.predict(img_path)\n",
        "                    prediction = result['prediction']\n",
        "                    confidence = result['confidence']\n",
        "\n",
        "                    results_summary[prediction] += 1\n",
        "                    confidence_scores[prediction].append(confidence)\n",
        "                    detailed_results.append({\n",
        "                        'image': img_path.name,\n",
        "                        'prediction': prediction,\n",
        "                        'confidence': confidence\n",
        "                    })\n",
        "\n",
        "                # Afficher r√©sum√©\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"RESUME DIAGNOSTIC LOT HYBRIDE\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "                total = len(images)\n",
        "                for stage in ['healthy', 'early', 'advanced']:\n",
        "                    count = results_summary.get(stage, 0)\n",
        "                    avg_conf = np.mean(confidence_scores[stage]) if confidence_scores[stage] else 0\n",
        "                    percentage = (count / total) * 100\n",
        "\n",
        "                    print(f\"{stage.upper()}: {count} images ({percentage:.1f}%)\")\n",
        "                    print(f\"  Confiance moyenne: {avg_conf:.2%}\")\n",
        "\n",
        "                # Sauvegarder r√©sultats d√©taill√©s\n",
        "                df = pd.DataFrame(detailed_results)\n",
        "                results_file = Path(CONFIG['results_dir']) / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "                df.to_csv(results_file, index=False)\n",
        "                print(f\"\\nüìÑ R√©sultats d√©taill√©s: {results_file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\nüìä EVALUATION COMPARATIVE\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez comparer performances syst√®me hybride vs r√®gles expertes\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"\\nüéØ ANALYSE FEATURES IMPORTANTES\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez analyser quelles features sont les plus importantes\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(\"\\nüëã Au revoir! Merci d'avoir utilis√© le syst√®me hybride!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main_hybrid()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n‚ö†Ô∏è Interruption utilisateur\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERREUR CRITIQUE: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lO5TKxcb7ML",
        "outputId": "ad11865f-5003-4ed1-fa13-b03dc37896ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\n",
            "D√©tection YOLO + Machine Learning pour Cancer du Sein\n",
            "SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\n",
            "================================================================================\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 991, in main_hybrid\n",
            "    X, y = hybrid_system.prepare_training_data(train_folder)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 392, in prepare_training_data\n",
            "    print(f\"Features par image: {X.shape[1]}\")\n",
            "                                 ~~~~~~~^^^\n",
            "IndexError: tuple index out of range\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 0\n",
            "Distribution des labels:\n",
            "\n",
            "Extraction des features...\n",
            "\n",
            "Features extraites: (0,)\n",
            "‚ùå ERREUR: tuple index out of range\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 991, in main_hybrid\n",
            "    X, y = hybrid_system.prepare_training_data(train_folder)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 392, in prepare_training_data\n",
            "    print(f\"Features par image: {X.shape[1]}\")\n",
            "                                 ~~~~~~~^^^\n",
            "IndexError: tuple index out of range\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 0\n",
            "Distribution des labels:\n",
            "\n",
            "Extraction des features...\n",
            "\n",
            "Features extraites: (0,)\n",
            "‚ùå ERREUR: tuple index out of range\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 991, in main_hybrid\n",
            "    X, y = hybrid_system.prepare_training_data(train_folder)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4-1113902059.py\", line 392, in prepare_training_data\n",
            "    print(f\"Features par image: {X.shape[1]}\")\n",
            "                                 ~~~~~~~^^^\n",
            "IndexError: tuple index out of range\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 0\n",
            "Distribution des labels:\n",
            "\n",
            "Extraction des features...\n",
            "\n",
            "Features extraites: (0,)\n",
            "‚ùå ERREUR: tuple index out of range\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n",
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 80\n",
            "Distribution des labels:\n",
            "  - healthy: 38\n",
            "  - advanced: 19\n",
            "  - early: 23\n",
            "\n",
            "Extraction des features...\n",
            "  Progression: 0/80\n",
            "  Progression: 10/80\n",
            "  Progression: 20/80\n",
            "  Progression: 30/80\n",
            "  Progression: 40/80\n",
            "  Progression: 50/80\n",
            "  Progression: 60/80\n",
            "  Progression: 70/80\n",
            "\n",
            "Features extraites: (80, 67)\n",
            "Features par image: 67\n",
            "\n",
            "ENTRAINEMENT DES CLASSIFICATEURS\n",
            "============================================================\n",
            "\n",
            "Entra√Ænement RandomForest...\n",
            "  Accuracy: 0.9375\n",
            "  CV Score: 0.7949 (+/- 0.1716)\n",
            "\n",
            "Rapport d√©taill√© RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    advanced       1.00      1.00      1.00         4\n",
            "       early       1.00      0.80      0.89         5\n",
            "     healthy       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.96      0.93      0.94        16\n",
            "weighted avg       0.95      0.94      0.94        16\n",
            "\n",
            "\n",
            "Entra√Ænement XGBoost...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7962 (+/- 0.1606)\n",
            "\n",
            "Entra√Ænement SVM...\n",
            "  Accuracy: 0.9375\n",
            "  CV Score: 0.8115 (+/- 0.1890)\n",
            "\n",
            "Entra√Ænement MLP...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7628 (+/- 0.2364)\n",
            "\n",
            "Entra√Ænement GradientBoosting...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7667 (+/- 0.2142)\n",
            "\n",
            "üèÜ MEILLEUR MODELE: SVM\n",
            "   Accuracy: 0.9375\n",
            "   CV Score: 0.8115\n",
            "\n",
            "Sauvegarde mod√®les dans mtc_classifiers\n",
            "‚úÖ Mod√®les sauvegard√©s\n",
            "\n",
            "‚úÖ ENTRAINEMENT TERMINE!\n",
            "Mod√®les sauvegard√©s dans: mtc_classifiers\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image: EBC_18_png_segmented_jpg.rf.8901f0ff6e62c2d923141bc0321a9ae2.jpg\n",
            "üéØ Pr√©diction: EARLY\n",
            "üìä Confiance: 84.13%\n",
            "ü§ñ Classificateur: SVM\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.0677 (6.77%)\n",
            "  - early: 0.8413 (84.13%)\n",
            "  - healthy: 0.0910 (9.10%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: healthy (0.623)\n",
            "  - XGBoost: early (0.599)\n",
            "  - SVM: advanced (0.370)\n",
            "  - MLP: healthy (1.000)\n",
            "  - GradientBoosting: early (1.000)\n",
            "\n",
            "üó∫Ô∏è Localisation par zones MTC:\n",
            "  - Rate-Estomac: 5 d√©tection(s)\n",
            "\n",
            "üìä Visualisation compl√®te: mtc_results/hybrid_mtc_EBC_18_png_segmented_jpg.rf.8901f0ff6e62c2d923141bc0321a9ae2_20250621_214558.png\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image: ABC_14_png_segmented_jpg.rf.441e8d59f6242cdbf8740950ec70791a.jpg\n",
            "üéØ Pr√©diction: ADVANCED\n",
            "üìä Confiance: 82.47%\n",
            "ü§ñ Classificateur: SVM\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.8247 (82.47%)\n",
            "  - early: 0.1307 (13.07%)\n",
            "  - healthy: 0.0446 (4.46%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: advanced (0.641)\n",
            "  - XGBoost: advanced (0.945)\n",
            "  - SVM: advanced (0.370)\n",
            "  - MLP: advanced (1.000)\n",
            "  - GradientBoosting: advanced (1.000)\n",
            "\n",
            "üó∫Ô∏è Localisation par zones MTC:\n",
            "  - Rate-Estomac: 9 d√©tection(s)\n",
            "  - Foie-VB Droit: 1 d√©tection(s)\n",
            "  - Foie-VB Gauche: 2 d√©tection(s)\n",
            "  - Coeur-Poumon: 6 d√©tection(s)\n",
            "\n",
            "üìä Visualisation compl√®te: mtc_results/hybrid_mtc_ABC_14_png_segmented_jpg.rf.441e8d59f6242cdbf8740950ec70791a_20250621_214805.png\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "‚ö†Ô∏è Interruption utilisateur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "\n",
        "# Configuration syst√®me optimis√©e\n",
        "CONFIG = {\n",
        "    'base_dir': '.',\n",
        "    'output_dir': 'mtc_output',\n",
        "    'model_dir': 'mtc_models',\n",
        "    'results_dir': 'mtc_results',\n",
        "    'classifier_dir': 'mtc_classifiers',\n",
        "    'train_split': 0.8,\n",
        "    'epochs': 200,\n",
        "    'batch_size': 16,\n",
        "    'imgsz': 640,\n",
        "    'patience': 50,\n",
        "    'conf_threshold': 0.15,\n",
        "    'iou_threshold': 0.3,\n",
        "    'augmentation_factor': 8,\n",
        "    'target_accuracy': 0.85,\n",
        "    'random_seed': 42,\n",
        "    'lr0': 0.0008,\n",
        "    'weight_decay': 0.001,\n",
        "    'mosaic': 0.8,\n",
        "    'mixup': 0.1,\n",
        "    'copy_paste': 0.1,\n",
        "    'tongue_conf_threshold': 0.5,  # Seuil pour d√©tection langue\n",
        "}\n",
        "\n",
        "# Classes YOLO (16 classes)\n",
        "CLASS_NAMES = [\n",
        "    'Ecchymoses', 'Eduit_jaune_epais', 'Eduit_jaune_mince', 'Fissure',\n",
        "    'Langue_normal', 'Langue_pale', 'Langue_petite', 'Langue_rose',\n",
        "    'Langue_rouge', 'Langue_rouge_foncee', 'enduit_blanc_epais',\n",
        "    'enduit_blanc_mince', 'langue_ganfelee', 'red_dot',\n",
        "    'salive_humide', 'salive_normale'\n",
        "]\n",
        "\n",
        "# Zones MTC\n",
        "TONGUE_ZONES = {\n",
        "    'kidney': {\n",
        "        'name': 'Rein',\n",
        "        'coords': [(0.2, 0), (0.8, 0), (0.8, 0.15), (0.2, 0.15)],\n",
        "        'color': (75, 0, 130)\n",
        "    },\n",
        "    'liver_gall_right': {\n",
        "        'name': 'Foie-VB Droit',\n",
        "        'coords': [(0, 0.15), (0.3, 0.15), (0.3, 0.65), (0, 0.65)],\n",
        "        'color': (34, 139, 34)\n",
        "    },\n",
        "    'liver_gall_left': {\n",
        "        'name': 'Foie-VB Gauche',\n",
        "        'coords': [(0.7, 0.15), (1, 0.15), (1, 0.65), (0.7, 0.65)],\n",
        "        'color': (50, 205, 50)\n",
        "    },\n",
        "    'spleen_stomach': {\n",
        "        'name': 'Rate-Estomac',\n",
        "        'coords': [(0.3, 0.15), (0.7, 0.15), (0.7, 0.65), (0.3, 0.65)],\n",
        "        'color': (255, 215, 0)\n",
        "    },\n",
        "    'heart_lung': {\n",
        "        'name': 'Coeur-Poumon',\n",
        "        'coords': [(0.2, 0.65), (0.8, 0.65), (0.8, 1), (0.2, 1)],\n",
        "        'color': (220, 20, 60)\n",
        "    }\n",
        "}\n",
        "\n",
        "class TongueDetector:\n",
        "    \"\"\"D√©tecteur de langue pour pr√©traitement\"\"\"\n",
        "\n",
        "    def __init__(self, tongue_model_path=None):\n",
        "        \"\"\"\n",
        "        Initialise le d√©tecteur de langue\n",
        "        tongue_model_path: chemin vers un mod√®le YOLO entra√Æn√© pour d√©tecter les langues\n",
        "        \"\"\"\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "        except ImportError:\n",
        "            print(\"Installation d'ultralytics...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ultralytics'])\n",
        "            from ultralytics import YOLO\n",
        "\n",
        "        if tongue_model_path and Path(tongue_model_path).exists():\n",
        "            self.model = YOLO(tongue_model_path)\n",
        "        else:\n",
        "            # Utiliser un mod√®le g√©n√©rique et filtrer par classe\n",
        "            self.model = YOLO('yolov8m.pt')  # Mod√®le medium pour meilleure pr√©cision\n",
        "\n",
        "        self.temp_dir = Path('temp_tongues')\n",
        "        self.temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def detect_and_extract_tongue(self, image_path, margin_percent=10):\n",
        "        \"\"\"\n",
        "        D√©tecte et extrait la r√©gion de la langue\n",
        "        margin_percent: pourcentage de marge √† ajouter autour de la d√©tection\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Charger image\n",
        "            image = cv2.imread(str(image_path))\n",
        "            if image is None:\n",
        "                print(f\"Impossible de charger l'image: {image_path}\")\n",
        "                return None, None\n",
        "\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # D√©tection YOLO\n",
        "            results = self.model(image_path, conf=CONFIG['tongue_conf_threshold'], verbose=False)\n",
        "\n",
        "            # Rechercher une d√©tection de langue\n",
        "            tongue_bbox = None\n",
        "            best_conf = 0\n",
        "\n",
        "            for r in results:\n",
        "                if r.boxes is not None:\n",
        "                    for box in r.boxes:\n",
        "                        # Si on a un mod√®le sp√©cifique langue, toute d√©tection est valide\n",
        "                        # Sinon, chercher des classes pertinentes (person, etc.)\n",
        "                        conf = float(box.conf)\n",
        "                        if conf > best_conf:\n",
        "                            best_conf = conf\n",
        "                            tongue_bbox = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "            # Si pas de d√©tection, essayer avec segmentation couleur\n",
        "            if tongue_bbox is None:\n",
        "                print(\"Pas de d√©tection YOLO, tentative de segmentation couleur...\")\n",
        "                tongue_bbox = self._segment_tongue_by_color(image)\n",
        "\n",
        "            if tongue_bbox is None:\n",
        "                print(\"Aucune langue d√©tect√©e, utilisation de l'image compl√®te\")\n",
        "                return str(image_path), None\n",
        "\n",
        "            # Extraire r√©gion avec marge\n",
        "            x1, y1, x2, y2 = tongue_bbox\n",
        "            margin_x = int((x2 - x1) * margin_percent / 100)\n",
        "            margin_y = int((y2 - y1) * margin_percent / 100)\n",
        "\n",
        "            # Appliquer marges avec limites\n",
        "            x1 = max(0, int(x1 - margin_x))\n",
        "            y1 = max(0, int(y1 - margin_y))\n",
        "            x2 = min(w, int(x2 + margin_x))\n",
        "            y2 = min(h, int(y2 + margin_y))\n",
        "\n",
        "            # Extraire r√©gion\n",
        "            tongue_region = image[y1:y2, x1:x2]\n",
        "\n",
        "            # Sauvegarder r√©gion extraite\n",
        "            temp_path = self.temp_dir / f\"tongue_{Path(image_path).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
        "            cv2.imwrite(str(temp_path), tongue_region)\n",
        "\n",
        "            return str(temp_path), (x1, y1, x2, y2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur d√©tection langue: {e}\")\n",
        "            return str(image_path), None\n",
        "\n",
        "    def _segment_tongue_by_color(self, image):\n",
        "        \"\"\"\n",
        "        Segmentation bas√©e couleur pour d√©tecter la langue\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convertir en HSV\n",
        "            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "            # Plages de couleur pour langue (rose/rouge)\n",
        "            lower_tongue = np.array([0, 30, 30])\n",
        "            upper_tongue = np.array([20, 255, 255])\n",
        "\n",
        "            # Masque pour tons roses/rouges\n",
        "            mask1 = cv2.inRange(hsv, lower_tongue, upper_tongue)\n",
        "\n",
        "            # Deuxi√®me plage pour tons plus fonc√©s\n",
        "            lower_tongue2 = np.array([160, 30, 30])\n",
        "            upper_tongue2 = np.array([180, 255, 255])\n",
        "            mask2 = cv2.inRange(hsv, lower_tongue2, upper_tongue2)\n",
        "\n",
        "            # Combiner masques\n",
        "            mask = cv2.bitwise_or(mask1, mask2)\n",
        "\n",
        "            # Morphologie pour nettoyer\n",
        "            kernel = np.ones((15, 15), np.uint8)\n",
        "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "            # Trouver contours\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if not contours:\n",
        "                return None\n",
        "\n",
        "            # Prendre le plus grand contour (probablement la langue)\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "            # V√©rifier que c'est assez grand\n",
        "            area = cv2.contourArea(largest_contour)\n",
        "            image_area = image.shape[0] * image.shape[1]\n",
        "\n",
        "            if area < 0.05 * image_area:  # Moins de 5% de l'image\n",
        "                return None\n",
        "\n",
        "            # Obtenir bounding box\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "            # V√©rifier ratio largeur/hauteur (langue g√©n√©ralement plus large que haute)\n",
        "            aspect_ratio = w / h\n",
        "            if aspect_ratio < 0.5 or aspect_ratio > 2.5:\n",
        "                return None\n",
        "\n",
        "            return np.array([x, y, x + w, y + h])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur segmentation couleur: {e}\")\n",
        "            return None\n",
        "\n",
        "    def cleanup_temp_files(self):\n",
        "        \"\"\"Nettoie les fichiers temporaires\"\"\"\n",
        "        if self.temp_dir.exists():\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "\n",
        "class YOLOFeatureExtractor:\n",
        "    \"\"\"Extracteur de features bas√© sur les d√©tections YOLO\"\"\"\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "        except ImportError:\n",
        "            print(\"Installation d'ultralytics...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ultralytics'])\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(model_path)\n",
        "\n",
        "        # Stocker derni√®res d√©tections pour visualisation\n",
        "        self.last_detections = []\n",
        "\n",
        "    def extract_features(self, image_path, return_detections=False):\n",
        "        \"\"\"Extrait features compl√®tes d'une image\"\"\"\n",
        "        try:\n",
        "            results = self.model(image_path, conf=CONFIG['conf_threshold'],\n",
        "                               iou=CONFIG['iou_threshold'], verbose=False)\n",
        "\n",
        "            image = cv2.imread(str(image_path))\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # Initialiser features\n",
        "            features = self._initialize_features()\n",
        "\n",
        "            # Traiter d√©tections\n",
        "            detections = []\n",
        "            for r in results:\n",
        "                if r.boxes is not None:\n",
        "                    for box in r.boxes:\n",
        "                        bbox = box.xyxy[0].cpu().numpy()\n",
        "                        conf = float(box.conf)\n",
        "                        cls = int(box.cls)\n",
        "\n",
        "                        if cls < len(CLASS_NAMES):\n",
        "                            detection = {\n",
        "                                'bbox': bbox,\n",
        "                                'confidence': conf,\n",
        "                                'class': cls,\n",
        "                                'class_name': CLASS_NAMES[cls]\n",
        "                            }\n",
        "                            detections.append(detection)\n",
        "\n",
        "            # Stocker d√©tections pour visualisation\n",
        "            self.last_detections = detections\n",
        "\n",
        "            # Extraire features des d√©tections\n",
        "            features = self._extract_detection_features(detections, features, w, h)\n",
        "            features = self._extract_spatial_features(detections, features, w, h)\n",
        "            features = self._extract_statistical_features(detections, features)\n",
        "            features = self._extract_zone_features(detections, features, w, h)\n",
        "\n",
        "            if return_detections:\n",
        "                return np.array(list(features.values())), detections\n",
        "            else:\n",
        "                return np.array(list(features.values()))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur extraction features: {e}\")\n",
        "            if return_detections:\n",
        "                return np.zeros(self._get_feature_count()), []\n",
        "            else:\n",
        "                return np.zeros(self._get_feature_count())\n",
        "\n",
        "    def get_last_detections(self):\n",
        "        \"\"\"Retourne derni√®res d√©tections YOLO\"\"\"\n",
        "        return self.last_detections\n",
        "\n",
        "    def _initialize_features(self):\n",
        "        \"\"\"Initialise toutes les features √† 0\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Features par classe (confidence max et count)\n",
        "        for class_name in CLASS_NAMES:\n",
        "            features[f'{class_name}_max_conf'] = 0.0\n",
        "            features[f'{class_name}_count'] = 0.0\n",
        "            features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        # Features spatiales\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            features[f'{zone}_detection_count'] = 0.0\n",
        "            features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        # Features statistiques globales\n",
        "        features['total_detections'] = 0.0\n",
        "        features['avg_confidence_all'] = 0.0\n",
        "        features['std_confidence'] = 0.0\n",
        "        features['detection_density'] = 0.0\n",
        "\n",
        "        # Features morphologiques\n",
        "        features['tongue_area_ratio'] = 0.0\n",
        "        features['detection_spread_x'] = 0.0\n",
        "        features['detection_spread_y'] = 0.0\n",
        "\n",
        "        # Features de co-occurrence\n",
        "        features['pathological_combinations'] = 0.0\n",
        "        features['healthy_indicators'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_detection_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features bas√©es sur les d√©tections\"\"\"\n",
        "        class_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            class_name = det['class_name']\n",
        "            conf = det['confidence']\n",
        "            class_detections[class_name].append(conf)\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            confs = class_detections[class_name]\n",
        "            if confs:\n",
        "                features[f'{class_name}_max_conf'] = max(confs)\n",
        "                features[f'{class_name}_count'] = len(confs)\n",
        "                features[f'{class_name}_avg_conf'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{class_name}_max_conf'] = 0.0\n",
        "                features[f'{class_name}_count'] = 0.0\n",
        "                features[f'{class_name}_avg_conf'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_spatial_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features spatiales et de zones\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        # Calculer centroids normalis√©s\n",
        "        centroids = []\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "            centroids.append((cx, cy))\n",
        "\n",
        "        # Spread spatial\n",
        "        if centroids:\n",
        "            x_coords = [c[0] for c in centroids]\n",
        "            y_coords = [c[1] for c in centroids]\n",
        "            features['detection_spread_x'] = np.std(x_coords) if len(x_coords) > 1 else 0\n",
        "            features['detection_spread_y'] = np.std(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_statistical_features(self, detections, features):\n",
        "        \"\"\"Extrait features statistiques globales\"\"\"\n",
        "        if not detections:\n",
        "            return features\n",
        "\n",
        "        confidences = [det['confidence'] for det in detections]\n",
        "\n",
        "        features['total_detections'] = len(detections)\n",
        "        features['avg_confidence_all'] = np.mean(confidences)\n",
        "        features['std_confidence'] = np.std(confidences)\n",
        "        features['detection_density'] = len(detections) / 100.0  # Normalis√©\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_zone_features(self, detections, features, w, h):\n",
        "        \"\"\"Extrait features par zone MTC\"\"\"\n",
        "        zone_detections = defaultdict(list)\n",
        "\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "\n",
        "            zone = self._find_zone(cx, cy)\n",
        "            if zone:\n",
        "                zone_detections[zone].append(det['confidence'])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            confs = zone_detections[zone]\n",
        "            if confs:\n",
        "                features[f'{zone}_detection_count'] = len(confs)\n",
        "                features[f'{zone}_avg_confidence'] = np.mean(confs)\n",
        "            else:\n",
        "                features[f'{zone}_detection_count'] = 0.0\n",
        "                features[f'{zone}_avg_confidence'] = 0.0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _find_zone(self, x, y):\n",
        "        \"\"\"Trouve zone pour coordonn√©es\"\"\"\n",
        "        for zone_name, zone_info in TONGUE_ZONES.items():\n",
        "            if self._point_in_polygon(x, y, zone_info['coords']):\n",
        "                return zone_name\n",
        "        return None\n",
        "\n",
        "    def _point_in_polygon(self, x, y, coords):\n",
        "        \"\"\"Test point dans polygone\"\"\"\n",
        "        n = len(coords)\n",
        "        inside = False\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            xi, yi = coords[i]\n",
        "            xj, yj = coords[j]\n",
        "            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "    def _get_feature_count(self):\n",
        "        \"\"\"Retourne le nombre total de features\"\"\"\n",
        "        # 3 features par classe (48) + 10 zones x 2 (20) + 7 globales + 2 morpho + 2 co-occur\n",
        "        return len(CLASS_NAMES) * 3 + len(TONGUE_ZONES) * 2 + 7 + 2 + 2\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        \"\"\"Retourne noms des features\"\"\"\n",
        "        names = []\n",
        "\n",
        "        # Features par classe\n",
        "        for class_name in CLASS_NAMES:\n",
        "            names.extend([\n",
        "                f'{class_name}_max_conf',\n",
        "                f'{class_name}_count',\n",
        "                f'{class_name}_avg_conf'\n",
        "            ])\n",
        "\n",
        "        # Features par zone\n",
        "        for zone in TONGUE_ZONES.keys():\n",
        "            names.extend([\n",
        "                f'{zone}_detection_count',\n",
        "                f'{zone}_avg_confidence'\n",
        "            ])\n",
        "\n",
        "        # Features globales\n",
        "        names.extend([\n",
        "            'total_detections', 'avg_confidence_all', 'std_confidence',\n",
        "            'detection_density', 'tongue_area_ratio', 'detection_spread_x',\n",
        "            'detection_spread_y', 'pathological_combinations', 'healthy_indicators'\n",
        "        ])\n",
        "\n",
        "        return names\n",
        "\n",
        "class HybridClassificationSystem:\n",
        "    \"\"\"Syst√®me hybride YOLO + Classification ML avec d√©tection de langue\"\"\"\n",
        "\n",
        "    def __init__(self, yolo_model_path, tongue_detector_model_path=None):\n",
        "        self.feature_extractor = YOLOFeatureExtractor(yolo_model_path)\n",
        "        self.tongue_detector = TongueDetector(tongue_detector_model_path)\n",
        "        self.classifiers = {}\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.is_trained = False\n",
        "\n",
        "        # Cr√©er dossier pour sauvegardes\n",
        "        self.classifier_dir = Path(CONFIG['classifier_dir'])\n",
        "        self.classifier_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def prepare_training_data(self, image_folder, labels_file=None, extract_tongue=True):\n",
        "        \"\"\"\n",
        "        Pr√©pare donn√©es d'entra√Ænement\n",
        "        extract_tongue: si True, extrait d'abord la langue avant analyse\n",
        "        \"\"\"\n",
        "        print(\"PREPARATION DES DONNEES D'ENTRAINEMENT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "\n",
        "        # Collecter images et labels\n",
        "        for img_path in Path(image_folder).glob('*.jpg'):\n",
        "            image_paths.append(img_path)\n",
        "\n",
        "            # Extraire label du nom de fichier\n",
        "            label = self._extract_label_from_filename(img_path.name)\n",
        "            labels.append(label)\n",
        "\n",
        "        print(f\"Images trouv√©es: {len(image_paths)}\")\n",
        "\n",
        "        # Distribution des labels\n",
        "        label_counts = defaultdict(int)\n",
        "        for label in labels:\n",
        "            label_counts[label] += 1\n",
        "\n",
        "        print(\"Distribution des labels:\")\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"  - {label}: {count}\")\n",
        "\n",
        "        # Extraire features\n",
        "        print(\"\\nExtraction des features...\")\n",
        "        features_list = []\n",
        "        valid_labels = []\n",
        "\n",
        "        for i, (img_path, label) in enumerate(zip(image_paths, labels)):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"  Progression: {i}/{len(image_paths)}\")\n",
        "\n",
        "            # Extraire langue si demand√©\n",
        "            if extract_tongue:\n",
        "                tongue_path, bbox = self.tongue_detector.detect_and_extract_tongue(img_path)\n",
        "                if tongue_path:\n",
        "                    features = self.feature_extractor.extract_features(tongue_path)\n",
        "                else:\n",
        "                    features = self.feature_extractor.extract_features(img_path)\n",
        "            else:\n",
        "                features = self.feature_extractor.extract_features(img_path)\n",
        "\n",
        "            if features is not None and not np.all(features == 0):\n",
        "                features_list.append(features)\n",
        "                valid_labels.append(label)\n",
        "\n",
        "        # Nettoyer fichiers temporaires\n",
        "        if extract_tongue:\n",
        "            self.tongue_detector.cleanup_temp_files()\n",
        "\n",
        "        X = np.array(features_list)\n",
        "        y = np.array(valid_labels)\n",
        "\n",
        "        print(f\"\\nFeatures extraites: {X.shape}\")\n",
        "        print(f\"Features par image: {X.shape[1]}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train_classifiers(self, X, y):\n",
        "        \"\"\"Entra√Æne plusieurs classificateurs\"\"\"\n",
        "        print(\"\\nENTRAINEMENT DES CLASSIFICATEURS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Encoder labels\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "\n",
        "        # Split train/test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=CONFIG['random_seed'],\n",
        "            stratify=y_encoded\n",
        "        )\n",
        "\n",
        "        # Normaliser features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # D√©finir classificateurs\n",
        "        classifiers_config = {\n",
        "            'RandomForest': {\n",
        "                'model': RandomForestClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=15,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model': xgb.XGBClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=8,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=CONFIG['random_seed'],\n",
        "                    n_jobs=-1\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            },\n",
        "            'SVM': {\n",
        "                'model': SVC(\n",
        "                    kernel='rbf',\n",
        "                    C=10,\n",
        "                    gamma='scale',\n",
        "                    probability=True,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'MLP': {\n",
        "                'model': MLPClassifier(\n",
        "                    hidden_layer_sizes=(128, 64, 32),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    alpha=0.001,\n",
        "                    learning_rate='adaptive',\n",
        "                    max_iter=500,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': True\n",
        "            },\n",
        "            'GradientBoosting': {\n",
        "                'model': GradientBoostingClassifier(\n",
        "                    n_estimators=200,\n",
        "                    learning_rate=0.1,\n",
        "                    max_depth=8,\n",
        "                    random_state=CONFIG['random_seed']\n",
        "                ),\n",
        "                'use_scaling': False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Entra√Æner et √©valuer chaque classificateur\n",
        "        results = {}\n",
        "\n",
        "        for name, config in classifiers_config.items():\n",
        "            print(f\"\\nEntra√Ænement {name}...\")\n",
        "\n",
        "            model = config['model']\n",
        "\n",
        "            if config['use_scaling']:\n",
        "                X_train_input = X_train_scaled\n",
        "                X_test_input = X_test_scaled\n",
        "            else:\n",
        "                X_train_input = X_train\n",
        "                X_test_input = X_test\n",
        "\n",
        "            # Entra√Æner\n",
        "            model.fit(X_train_input, y_train)\n",
        "\n",
        "            # Pr√©dictions\n",
        "            y_pred = model.predict(X_test_input)\n",
        "            y_pred_proba = model.predict_proba(X_test_input)\n",
        "\n",
        "            # M√©triques\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            # Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_input, y_train, cv=5)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'accuracy': accuracy,\n",
        "                'cv_mean': cv_scores.mean(),\n",
        "                'cv_std': cv_scores.std(),\n",
        "                'use_scaling': config['use_scaling']\n",
        "            }\n",
        "\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "            # Rapport d√©taill√© pour le meilleur mod√®le\n",
        "            if name == 'RandomForest':  # Afficher d√©tails pour RF\n",
        "                print(f\"\\nRapport d√©taill√© {name}:\")\n",
        "                class_names = self.label_encoder.classes_\n",
        "                print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "        # S√©lectionner meilleur mod√®le\n",
        "        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
        "        best_model_info = results[best_name]\n",
        "\n",
        "        print(f\"\\nüèÜ MEILLEUR MODELE: {best_name}\")\n",
        "        print(f\"   Accuracy: {best_model_info['accuracy']:.4f}\")\n",
        "        print(f\"   CV Score: {best_model_info['cv_mean']:.4f}\")\n",
        "\n",
        "        # Sauvegarder mod√®les\n",
        "        self.classifiers = results\n",
        "        self.best_classifier_name = best_name\n",
        "        self.is_trained = True\n",
        "\n",
        "        # Sauvegarder sur disque\n",
        "        self.save_models()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict(self, image_path, return_probabilities=False, extract_tongue=True):\n",
        "        \"\"\"\n",
        "        Pr√©diction hybride YOLO + Classification\n",
        "        extract_tongue: si True, extrait d'abord la langue\n",
        "        \"\"\"\n",
        "        if not self.is_trained:\n",
        "            self.load_models()\n",
        "\n",
        "        original_image_path = image_path\n",
        "        tongue_bbox = None\n",
        "\n",
        "        # Extraire langue si demand√©\n",
        "        if extract_tongue:\n",
        "            print(\"üîç D√©tection de la langue...\")\n",
        "            tongue_path, tongue_bbox = self.tongue_detector.detect_and_extract_tongue(image_path)\n",
        "            if tongue_path:\n",
        "                print(\"‚úÖ Langue d√©tect√©e et extraite\")\n",
        "                image_path = tongue_path\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Pas de langue d√©tect√©e, analyse de l'image compl√®te\")\n",
        "\n",
        "        # Extraire features avec YOLO et r√©cup√©rer d√©tections\n",
        "        features, detections = self.feature_extractor.extract_features(image_path, return_detections=True)\n",
        "\n",
        "        if features is None or np.all(features == 0):\n",
        "            return {\n",
        "                'prediction': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'probabilities': {},\n",
        "                'detections': [],\n",
        "                'detected_features': {},\n",
        "                'error': 'Aucune feature extraite',\n",
        "                'tongue_detected': tongue_bbox is not None,\n",
        "                'original_image': str(original_image_path),\n",
        "                'analyzed_image': str(image_path)\n",
        "            }\n",
        "\n",
        "        # Utiliser le meilleur classificateur\n",
        "        best_clf_info = self.classifiers[self.best_classifier_name]\n",
        "        model = best_clf_info['model']\n",
        "        use_scaling = best_clf_info['use_scaling']\n",
        "\n",
        "        # Pr√©parer features\n",
        "        features_reshaped = features.reshape(1, -1)\n",
        "        if use_scaling:\n",
        "            features_reshaped = self.scaler.transform(features_reshaped)\n",
        "\n",
        "        # Pr√©diction\n",
        "        prediction_encoded = model.predict(features_reshaped)[0]\n",
        "        prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "\n",
        "        # Probabilit√©s\n",
        "        probabilities = model.predict_proba(features_reshaped)[0]\n",
        "        prob_dict = {}\n",
        "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
        "            prob_dict[class_name] = probabilities[i]\n",
        "\n",
        "        confidence = max(probabilities)\n",
        "\n",
        "        # Extraire features significatives pour affichage\n",
        "        feature_names = self.feature_extractor.get_feature_names()\n",
        "        detected_features = {}\n",
        "        for i, (name, value) in enumerate(zip(feature_names, features)):\n",
        "            if value > 0 and 'count' not in name.lower():  # Exclure les counts pour lisibilit√©\n",
        "                detected_features[name] = value\n",
        "\n",
        "        # Trier par importance\n",
        "        detected_features = dict(sorted(detected_features.items(),\n",
        "                                      key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        result = {\n",
        "            'prediction': prediction,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': prob_dict,\n",
        "            'classifier_used': self.best_classifier_name,\n",
        "            'detections': detections,\n",
        "            'detected_features': detected_features,\n",
        "            'tongue_detected': tongue_bbox is not None,\n",
        "            'tongue_bbox': tongue_bbox,\n",
        "            'original_image': str(original_image_path),\n",
        "            'analyzed_image': str(image_path)\n",
        "        }\n",
        "\n",
        "        if return_probabilities:\n",
        "            result['all_classifier_predictions'] = self._get_ensemble_predictions(features_reshaped)\n",
        "\n",
        "        # Nettoyer fichiers temporaires si extraction langue\n",
        "        if extract_tongue and tongue_bbox is not None:\n",
        "            # Garder le fichier temporaire pour visualisation\n",
        "            pass\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _get_ensemble_predictions(self, features):\n",
        "        \"\"\"Pr√©dictions ensemble de tous les classificateurs\"\"\"\n",
        "        ensemble_results = {}\n",
        "\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model = clf_info['model']\n",
        "            use_scaling = clf_info['use_scaling']\n",
        "\n",
        "            features_input = self.scaler.transform(features) if use_scaling else features\n",
        "\n",
        "            prediction_encoded = model.predict(features_input)[0]\n",
        "            prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]\n",
        "            probabilities = model.predict_proba(features_input)[0]\n",
        "\n",
        "            ensemble_results[name] = {\n",
        "                'prediction': prediction,\n",
        "                'confidence': max(probabilities),\n",
        "                'probabilities': dict(zip(self.label_encoder.classes_, probabilities))\n",
        "            }\n",
        "\n",
        "        return ensemble_results\n",
        "\n",
        "    def save_models(self):\n",
        "        \"\"\"Sauvegarde mod√®les et preprocessing\"\"\"\n",
        "        print(f\"\\nSauvegarde mod√®les dans {self.classifier_dir}\")\n",
        "\n",
        "        # Sauvegarder chaque classificateur\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            joblib.dump(clf_info['model'], model_path)\n",
        "\n",
        "        # Sauvegarder preprocessing\n",
        "        joblib.dump(self.scaler, self.classifier_dir / \"scaler.joblib\")\n",
        "        joblib.dump(self.label_encoder, self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Sauvegarder config\n",
        "        config = {\n",
        "            'best_classifier': self.best_classifier_name,\n",
        "            'classifiers_config': {name: {'use_scaling': info['use_scaling']}\n",
        "                                 for name, info in self.classifiers.items()},\n",
        "            'feature_names': self.feature_extractor.get_feature_names()\n",
        "        }\n",
        "\n",
        "        with open(self.classifier_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"‚úÖ Mod√®les sauvegard√©s\")\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Charge mod√®les sauvegard√©s\"\"\"\n",
        "        config_path = self.classifier_dir / \"config.json\"\n",
        "\n",
        "        if not config_path.exists():\n",
        "            raise FileNotFoundError(\"Aucun mod√®le sauvegard√© trouv√©\")\n",
        "\n",
        "        print(\"Chargement mod√®les sauvegard√©s...\")\n",
        "\n",
        "        # Charger config\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        self.best_classifier_name = config['best_classifier']\n",
        "\n",
        "        # Charger preprocessing\n",
        "        self.scaler = joblib.load(self.classifier_dir / \"scaler.joblib\")\n",
        "        self.label_encoder = joblib.load(self.classifier_dir / \"label_encoder.joblib\")\n",
        "\n",
        "        # Charger classificateurs\n",
        "        self.classifiers = {}\n",
        "        for name, clf_config in config['classifiers_config'].items():\n",
        "            model_path = self.classifier_dir / f\"{name}_model.joblib\"\n",
        "            if model_path.exists():\n",
        "                model = joblib.load(model_path)\n",
        "                self.classifiers[name] = {\n",
        "                    'model': model,\n",
        "                    'use_scaling': clf_config['use_scaling']\n",
        "                }\n",
        "\n",
        "        self.is_trained = True\n",
        "        print(\"‚úÖ Mod√®les charg√©s\")\n",
        "\n",
        "    def _extract_label_from_filename(self, filename):\n",
        "        \"\"\"Extrait label du nom de fichier\"\"\"\n",
        "        filename_lower = filename.lower()\n",
        "\n",
        "        if any(keyword in filename_lower for keyword in ['healthy', 'sain', 'normal']):\n",
        "            return 'healthy'\n",
        "        elif any(keyword in filename_lower for keyword in ['ebc', 'early', 'precoce']):\n",
        "            return 'early'\n",
        "        elif any(keyword in filename_lower for keyword in ['abc', 'advanced', 'avance']):\n",
        "            return 'advanced'\n",
        "        elif any(keyword in filename_lower for keyword in ['real']):\n",
        "            if any(keyword in filename_lower for keyword in ['1', 'one', 'first']):\n",
        "                return 'healthy'\n",
        "            elif any(keyword in filename_lower for keyword in ['2', 'two', 'second']):\n",
        "                return 'early'\n",
        "            elif any(keyword in filename_lower for keyword in ['3', 'three', 'third']):\n",
        "                return 'advanced'\n",
        "            else:\n",
        "                return 'unknown'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "class HybridDiagnosticVisualizer:\n",
        "    \"\"\"Visualiseur pour syst√®me hybride avec cartographie MTC\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results_dir = Path(CONFIG['results_dir'])\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "        self.zones = TONGUE_ZONES\n",
        "\n",
        "    def create_comprehensive_visualization(self, image_path, yolo_detections, ml_result, feature_extractor=None):\n",
        "        \"\"\"Cr√©e visualisation compl√®te avec cartographie MTC\"\"\"\n",
        "        # Charger images\n",
        "        original_image = cv2.imread(str(ml_result.get('original_image', image_path)))\n",
        "        analyzed_image = cv2.imread(str(ml_result.get('analyzed_image', image_path)))\n",
        "\n",
        "        if analyzed_image is None:\n",
        "            analyzed_image = original_image\n",
        "\n",
        "        # R√©cup√©rer les d√©tections YOLO brutes si n√©cessaire\n",
        "        if yolo_detections is None:\n",
        "            yolo_detections = self._get_yolo_detections(ml_result['analyzed_image'], feature_extractor)\n",
        "\n",
        "        # Cr√©er figure avec 4 subplots si langue d√©tect√©e, sinon 3\n",
        "        if ml_result.get('tongue_detected', False):\n",
        "            fig = plt.figure(figsize=(24, 10))\n",
        "            num_cols = 4\n",
        "        else:\n",
        "            fig = plt.figure(figsize=(20, 10))\n",
        "            num_cols = 3\n",
        "\n",
        "        current_col = 1\n",
        "\n",
        "        # 1. Image originale avec d√©tection langue (si applicable)\n",
        "        if ml_result.get('tongue_detected', False):\n",
        "            ax0 = plt.subplot(1, num_cols, current_col)\n",
        "            ax0.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
        "            ax0.set_title('Image Originale + D√©tection Langue', fontsize=14, fontweight='bold')\n",
        "\n",
        "            # Afficher bbox de la langue d√©tect√©e\n",
        "            if ml_result.get('tongue_bbox'):\n",
        "                x1, y1, x2, y2 = ml_result['tongue_bbox']\n",
        "                rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                               linewidth=3, edgecolor='lime', facecolor='none')\n",
        "                ax0.add_patch(rect)\n",
        "                ax0.text(x1, y1-10, \"Langue D√©tect√©e\", color='white',\n",
        "                        backgroundcolor='lime', fontsize=10, weight='bold')\n",
        "\n",
        "            ax0.axis('off')\n",
        "            current_col += 1\n",
        "\n",
        "        # 2. Image analys√©e avec d√©tections YOLO et bounding boxes\n",
        "        ax1 = plt.subplot(1, num_cols, current_col)\n",
        "        ax1.imshow(cv2.cvtColor(analyzed_image, cv2.COLOR_BGR2RGB))\n",
        "        ax1.set_title('D√©tections YOLO sur Langue', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Ajouter bounding boxes avec labels\n",
        "        for det in yolo_detections:\n",
        "            bbox = det['bbox']\n",
        "            x1, y1, x2, y2 = bbox\n",
        "\n",
        "            color = self._get_color_for_class(det['class_name'])\n",
        "\n",
        "            # Rectangle de d√©tection\n",
        "            rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                           linewidth=2, edgecolor=color, facecolor='none')\n",
        "            ax1.add_patch(rect)\n",
        "\n",
        "            # Label avec confiance\n",
        "            label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
        "            ax1.text(x1, y1-5, label, color='white', backgroundcolor=color,\n",
        "                    fontsize=8, weight='bold')\n",
        "\n",
        "        ax1.axis('off')\n",
        "        current_col += 1\n",
        "\n",
        "        # 3. Cartographie MTC avec zones et d√©tections\n",
        "        ax2 = plt.subplot(1, num_cols, current_col)\n",
        "        ax2.set_xlim(0, 1)\n",
        "        ax2.set_ylim(1, 0)  # Inverser Y pour correspondre √† l'image\n",
        "        ax2.set_aspect('equal')\n",
        "        ax2.set_title('Cartographie MTC', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Dessiner zones MTC\n",
        "        zone_counts = defaultdict(int)\n",
        "        for zone_name, zone_info in self.zones.items():\n",
        "            coords = zone_info['coords']\n",
        "            color = np.array(zone_info['color']) / 255.0\n",
        "\n",
        "            # Polygone de zone\n",
        "            polygon = Polygon(coords, facecolor=color, alpha=0.3,\n",
        "                            edgecolor='black', linewidth=2)\n",
        "            ax2.add_patch(polygon)\n",
        "\n",
        "            # Nom de zone au centre\n",
        "            cx = np.mean([c[0] for c in coords])\n",
        "            cy = np.mean([c[1] for c in coords])\n",
        "            ax2.text(cx, cy, zone_info['name'], ha='center', va='center',\n",
        "                    fontsize=11, weight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
        "\n",
        "        # Projeter d√©tections sur cartographie\n",
        "        h, w = analyzed_image.shape[:2]\n",
        "        for det in yolo_detections:\n",
        "            bbox = det['bbox']\n",
        "            # Calculer centre de la d√©tection\n",
        "            cx = ((bbox[0] + bbox[2]) / 2) / w\n",
        "            cy = ((bbox[1] + bbox[3]) / 2) / h\n",
        "\n",
        "            # Trouver zone correspondante\n",
        "            zone = self._find_zone(cx, cy)\n",
        "            if zone:\n",
        "                zone_counts[zone] += 1\n",
        "\n",
        "            # Afficher d√©tection sur cartographie\n",
        "            color = self._get_color_for_class(det['class_name'])\n",
        "            ax2.scatter(cx, cy, s=150, c=color, marker='x', linewidths=4, alpha=0.8)\n",
        "\n",
        "            # Ajouter label pr√®s du point\n",
        "            ax2.text(cx+0.02, cy, det['class_name'][:8], fontsize=8,\n",
        "                    color=color, weight='bold')\n",
        "\n",
        "        ax2.set_xlabel('Gauche ‚Üê ‚Üí Droite', fontsize=10)\n",
        "        ax2.set_ylabel('Avant ‚Üê ‚Üí Arri√®re', fontsize=10)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        current_col += 1\n",
        "\n",
        "        # 4. Diagnostic final avec d√©tails\n",
        "        ax3 = plt.subplot(1, num_cols, current_col)\n",
        "        ax3.axis('off')\n",
        "\n",
        "        prediction = ml_result['prediction']\n",
        "        confidence = ml_result['confidence']\n",
        "        classifier = ml_result['classifier_used']\n",
        "\n",
        "        # Couleurs et messages selon diagnostic\n",
        "        if prediction == 'healthy':\n",
        "            color = 'green'\n",
        "            message = \"LANGUE SAINE\\nAucun signe pathologique\"\n",
        "        elif prediction == 'early':\n",
        "            color = 'orange'\n",
        "            message = \"STADE PRECOCE (EBC)\\nSignes initiaux d√©tect√©s\"\n",
        "        else:\n",
        "            color = 'red'\n",
        "            message = \"STADE AVANCE (ABC)\\nSignes pathologiques importants\"\n",
        "\n",
        "        # Titre diagnostic\n",
        "        ax3.text(0.5, 0.95, 'DIAGNOSTIC MTC HYBRIDE', ha='center', fontsize=16,\n",
        "                weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        # Statut d√©tection langue\n",
        "        if ml_result.get('tongue_detected'):\n",
        "            ax3.text(0.5, 0.88, '‚úÖ Langue d√©tect√©e et extraite', ha='center',\n",
        "                    fontsize=10, color='green', transform=ax3.transAxes)\n",
        "        else:\n",
        "            ax3.text(0.5, 0.88, '‚ö†Ô∏è Analyse sur image compl√®te', ha='center',\n",
        "                    fontsize=10, color='orange', transform=ax3.transAxes)\n",
        "\n",
        "        # R√©sultat principal\n",
        "        ax3.text(0.5, 0.78, message, ha='center', fontsize=12,\n",
        "                color=color, weight='bold', transform=ax3.transAxes,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=color, alpha=0.1))\n",
        "\n",
        "        # Confiance\n",
        "        ax3.text(0.5, 0.63, f'Confiance: {confidence:.1%}', ha='center',\n",
        "                fontsize=12, weight='bold', transform=ax3.transAxes)\n",
        "\n",
        "        # Classificateur utilis√©\n",
        "        ax3.text(0.5, 0.55, f'Classificateur: {classifier}', ha='center',\n",
        "                fontsize=10, style='italic', transform=ax3.transAxes)\n",
        "\n",
        "        # Scores d√©taill√©s\n",
        "        y_pos = 0.45\n",
        "        ax3.text(0.1, y_pos, 'Scores d√©taill√©s:', fontsize=11, weight='bold',\n",
        "                transform=ax3.transAxes)\n",
        "\n",
        "        for stage, prob in ml_result['probabilities'].items():\n",
        "            y_pos -= 0.06\n",
        "            stage_color = 'green' if stage == 'healthy' else 'orange' if stage == 'early' else 'red'\n",
        "            ax3.text(0.15, y_pos, f'{stage}: {prob:.1%}', fontsize=10,\n",
        "                    color=stage_color, transform=ax3.transAxes)\n",
        "\n",
        "        # Localisation par zones\n",
        "        if zone_counts:\n",
        "            y_pos -= 0.08\n",
        "            ax3.text(0.1, y_pos, 'Localisation MTC:', fontsize=11, weight='bold',\n",
        "                    transform=ax3.transAxes)\n",
        "\n",
        "            for zone, count in zone_counts.items():\n",
        "                if count > 0:\n",
        "                    y_pos -= 0.05\n",
        "                    zone_name = self.zones[zone]['name']\n",
        "                    ax3.text(0.15, y_pos, f'{zone_name}: {count}', fontsize=9,\n",
        "                            transform=ax3.transAxes)\n",
        "\n",
        "        # Caract√©ristiques d√©tect√©es\n",
        "        if 'detected_features' in ml_result and y_pos > 0.1:\n",
        "            y_pos -= 0.08\n",
        "            ax3.text(0.1, y_pos, 'Caract√©ristiques:', fontsize=11, weight='bold',\n",
        "                    transform=ax3.transAxes)\n",
        "\n",
        "            features = ml_result['detected_features']\n",
        "            for feature, score in list(features.items())[:4]:  # Top 4\n",
        "                if score > 0 and y_pos > 0.05:\n",
        "                    y_pos -= 0.04\n",
        "                    ax3.text(0.15, y_pos, f'{feature}: {score:.2f}', fontsize=8,\n",
        "                            transform=ax3.transAxes)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Sauvegarder\n",
        "        save_path = self.results_dir / f\"hybrid_mtc_{Path(image_path).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return save_path, zone_counts\n",
        "\n",
        "    def _get_yolo_detections(self, image_path, feature_extractor=None):\n",
        "        \"\"\"R√©cup√®re d√©tections YOLO brutes si pas fournies\"\"\"\n",
        "        if feature_extractor:\n",
        "            _, detections = feature_extractor.extract_features(image_path, return_detections=True)\n",
        "            return detections\n",
        "        else:\n",
        "            # Fallback : essayer de cr√©er un extracteur temporaire\n",
        "            try:\n",
        "                from ultralytics import YOLO\n",
        "                model = YOLO('yolov8s.pt')  # Mod√®le par d√©faut\n",
        "                results = model(image_path, conf=CONFIG['conf_threshold'], verbose=False)\n",
        "\n",
        "                detections = []\n",
        "                for r in results:\n",
        "                    if r.boxes is not None:\n",
        "                        for box in r.boxes:\n",
        "                            bbox = box.xyxy[0].cpu().numpy()\n",
        "                            conf = float(box.conf)\n",
        "                            cls = int(box.cls)\n",
        "\n",
        "                            if cls < len(CLASS_NAMES):\n",
        "                                detection = {\n",
        "                                    'bbox': bbox,\n",
        "                                    'confidence': conf,\n",
        "                                    'class': cls,\n",
        "                                    'class_name': CLASS_NAMES[cls]\n",
        "                                }\n",
        "                                detections.append(detection)\n",
        "                return detections\n",
        "            except:\n",
        "                return []\n",
        "\n",
        "    def _get_color_for_class(self, class_name):\n",
        "        \"\"\"Retourne couleur selon classe\"\"\"\n",
        "        if any(x in class_name for x in ['normal', 'rose', 'salive_normale']):\n",
        "            return 'green'\n",
        "        elif any(x in class_name for x in ['pale', 'blanc_mince', 'jaune_mince']):\n",
        "            return 'orange'\n",
        "        elif any(x in class_name for x in ['rouge_foncee', 'jaune_epais', 'Ecchymoses']):\n",
        "            return 'red'\n",
        "        elif any(x in class_name for x in ['rouge', 'blanc_epais']):\n",
        "            return 'darkorange'\n",
        "        elif 'red_dot' in class_name:\n",
        "            return 'crimson'\n",
        "        elif 'Fissure' in class_name:\n",
        "            return 'purple'\n",
        "        else:\n",
        "            return 'gray'\n",
        "\n",
        "    def _find_zone(self, x, y):\n",
        "        \"\"\"Trouve zone MTC pour coordonn√©es\"\"\"\n",
        "        for zone_name, zone_info in self.zones.items():\n",
        "            if self._point_in_polygon(x, y, zone_info['coords']):\n",
        "                return zone_name\n",
        "        return None\n",
        "\n",
        "    def _point_in_polygon(self, x, y, coords):\n",
        "        \"\"\"Test point dans polygone\"\"\"\n",
        "        n = len(coords)\n",
        "        inside = False\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            xi, yi = coords[i]\n",
        "            xj, yj = coords[j]\n",
        "            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "def main_hybrid():\n",
        "    \"\"\"Programme principal syst√®me hybride avec d√©tection de langue\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\")\n",
        "    print(\"Avec D√©tection Automatique de Langue\")\n",
        "    print(\"SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Configuration seeds\n",
        "    random.seed(CONFIG['random_seed'])\n",
        "    np.random.seed(CONFIG['random_seed'])\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nMENU SYSTEME HYBRIDE\")\n",
        "        print(\"-\"*40)\n",
        "        print(\"1. Entra√Æner syst√®me hybride\")\n",
        "        print(\"2. Diagnostic hybride (image unique)\")\n",
        "        print(\"3. Diagnostic hybride (lot)\")\n",
        "        print(\"4. √âvaluation comparative\")\n",
        "        print(\"5. Analyser features importantes\")\n",
        "        print(\"6. Quitter\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        choice = input(\"Choix (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\nüîÑ ENTRAINEMENT SYSTEME HYBRIDE\")\n",
        "\n",
        "            # V√©rifier mod√®le YOLO\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO pathologies: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Mod√®le d√©tection langue (optionnel)\n",
        "            tongue_model = input(\"Chemin mod√®le YOLO langue (Enter pour segmentation couleur): \").strip()\n",
        "            if tongue_model and not Path(tongue_model).exists():\n",
        "                print(\"‚ö†Ô∏è Mod√®le langue non trouv√©, utilisation segmentation couleur\")\n",
        "                tongue_model = None\n",
        "\n",
        "            # Dossier images d'entra√Ænement\n",
        "            train_folder = input(\"Dossier images d'entra√Ænement: \").strip()\n",
        "            if not Path(train_folder).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Demander si extraction langue\n",
        "            extract_tongue = input(\"Extraire langue avant analyse? (o/n) [o]: \").strip().lower()\n",
        "            extract_tongue = extract_tongue != 'n'\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model, tongue_model)\n",
        "\n",
        "                # Pr√©parer donn√©es\n",
        "                X, y = hybrid_system.prepare_training_data(train_folder, extract_tongue=extract_tongue)\n",
        "\n",
        "                if len(X) == 0:\n",
        "                    print(\"‚ùå Aucune donn√©e d'entra√Ænement valide\")\n",
        "                    continue\n",
        "\n",
        "                # Entra√Æner\n",
        "                results = hybrid_system.train_classifiers(X, y)\n",
        "\n",
        "                print(\"\\n‚úÖ ENTRAINEMENT TERMINE!\")\n",
        "                print(f\"Mod√®les sauvegard√©s dans: {hybrid_system.classifier_dir}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nüîç DIAGNOSTIC HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO pathologies: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Mod√®le d√©tection langue (optionnel)\n",
        "            tongue_model = input(\"Chemin mod√®le YOLO langue (Enter pour segmentation couleur): \").strip()\n",
        "            if tongue_model and not Path(tongue_model).exists():\n",
        "                print(\"‚ö†Ô∏è Mod√®le langue non trouv√©, utilisation segmentation couleur\")\n",
        "                tongue_model = None\n",
        "\n",
        "            image_path = input(\"Chemin image: \").strip().strip('\"')\n",
        "            if not Path(image_path).exists():\n",
        "                print(\"‚ùå Image non trouv√©e\")\n",
        "                continue\n",
        "\n",
        "            # Demander si extraction langue\n",
        "            extract_tongue = input(\"Extraire langue avant analyse? (o/n) [o]: \").strip().lower()\n",
        "            extract_tongue = extract_tongue != 'n'\n",
        "\n",
        "            try:\n",
        "                # Initialiser syst√®me\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model, tongue_model)\n",
        "\n",
        "                # Diagnostic\n",
        "                result = hybrid_system.predict(image_path, return_probabilities=True,\n",
        "                                             extract_tongue=extract_tongue)\n",
        "\n",
        "                # Afficher r√©sultats\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"DIAGNOSTIC HYBRIDE YOLO + ML\")\n",
        "                print(\"=\"*60)\n",
        "                print(f\"üì∏ Image originale: {Path(result['original_image']).name}\")\n",
        "                if result['tongue_detected']:\n",
        "                    print(f\"‚úÖ Langue d√©tect√©e et extraite\")\n",
        "                    print(f\"üì∏ Image analys√©e: {Path(result['analyzed_image']).name}\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Pas de langue d√©tect√©e, analyse sur image compl√®te\")\n",
        "\n",
        "                print(f\"\\nüéØ Pr√©diction: {result['prediction'].upper()}\")\n",
        "                print(f\"üìä Confiance: {result['confidence']:.2%}\")\n",
        "                print(f\"ü§ñ Classificateur: {result['classifier_used']}\")\n",
        "\n",
        "                print(\"\\nüìà Probabilit√©s d√©taill√©es:\")\n",
        "                for class_name, prob in result['probabilities'].items():\n",
        "                    print(f\"  - {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
        "\n",
        "                if 'all_classifier_predictions' in result:\n",
        "                    print(\"\\nüîÑ Pr√©dictions ensemble:\")\n",
        "                    for clf_name, clf_result in result['all_classifier_predictions'].items():\n",
        "                        print(f\"  - {clf_name}: {clf_result['prediction']} ({clf_result['confidence']:.3f})\")\n",
        "\n",
        "                # Visualisation avec cartographie MTC\n",
        "                visualizer = HybridDiagnosticVisualizer()\n",
        "                save_path, zone_counts = visualizer.create_comprehensive_visualization(\n",
        "                    image_path, result['detections'], result, hybrid_system.feature_extractor\n",
        "                )\n",
        "\n",
        "                # Afficher informations zones\n",
        "                if zone_counts:\n",
        "                    print(\"\\nüó∫Ô∏è Localisation par zones MTC:\")\n",
        "                    for zone, count in zone_counts.items():\n",
        "                        if count > 0:\n",
        "                            zone_name = TONGUE_ZONES[zone]['name']\n",
        "                            print(f\"  - {zone_name}: {count} d√©tection(s)\")\n",
        "\n",
        "                print(f\"\\nüìä Visualisation compl√®te: {save_path}\")\n",
        "\n",
        "                # Nettoyer fichiers temporaires\n",
        "                if extract_tongue:\n",
        "                    cleanup = input(\"\\nNettoyer fichiers temporaires? (o/n) [n]: \").strip().lower()\n",
        "                    if cleanup == 'o':\n",
        "                        hybrid_system.tongue_detector.cleanup_temp_files()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nüìÅ DIAGNOSTIC LOT HYBRIDE\")\n",
        "\n",
        "            yolo_model = input(\"Chemin mod√®le YOLO pathologies: \").strip()\n",
        "            if not Path(yolo_model).exists():\n",
        "                print(\"‚ùå Mod√®le YOLO non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Mod√®le d√©tection langue (optionnel)\n",
        "            tongue_model = input(\"Chemin mod√®le YOLO langue (Enter pour segmentation couleur): \").strip()\n",
        "            if tongue_model and not Path(tongue_model).exists():\n",
        "                print(\"‚ö†Ô∏è Mod√®le langue non trouv√©, utilisation segmentation couleur\")\n",
        "                tongue_model = None\n",
        "\n",
        "            folder_path = input(\"Dossier images: \").strip().strip('\"')\n",
        "            if not Path(folder_path).exists():\n",
        "                print(\"‚ùå Dossier non trouv√©\")\n",
        "                continue\n",
        "\n",
        "            # Demander si extraction langue\n",
        "            extract_tongue = input(\"Extraire langue avant analyse? (o/n) [o]: \").strip().lower()\n",
        "            extract_tongue = extract_tongue != 'n'\n",
        "\n",
        "            try:\n",
        "                hybrid_system = HybridClassificationSystem(yolo_model, tongue_model)\n",
        "                images = list(Path(folder_path).glob('*.jpg'))\n",
        "\n",
        "                if not images:\n",
        "                    print(\"‚ùå Aucune image .jpg trouv√©e\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"\\nüîÑ Traitement de {len(images)} images...\")\n",
        "\n",
        "                results_summary = defaultdict(int)\n",
        "                confidence_scores = defaultdict(list)\n",
        "                detailed_results = []\n",
        "                tongue_detection_stats = {'detected': 0, 'not_detected': 0}\n",
        "\n",
        "                for i, img_path in enumerate(images):\n",
        "                    print(f\"  Progression: {i+1}/{len(images)} - {img_path.name}\")\n",
        "\n",
        "                    result = hybrid_system.predict(img_path, extract_tongue=extract_tongue)\n",
        "                    prediction = result['prediction']\n",
        "                    confidence = result['confidence']\n",
        "\n",
        "                    results_summary[prediction] += 1\n",
        "                    confidence_scores[prediction].append(confidence)\n",
        "\n",
        "                    if result['tongue_detected']:\n",
        "                        tongue_detection_stats['detected'] += 1\n",
        "                    else:\n",
        "                        tongue_detection_stats['not_detected'] += 1\n",
        "\n",
        "                    detailed_results.append({\n",
        "                        'image': img_path.name,\n",
        "                        'prediction': prediction,\n",
        "                        'confidence': confidence,\n",
        "                        'tongue_detected': result['tongue_detected']\n",
        "                    })\n",
        "\n",
        "                # Afficher r√©sum√©\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"RESUME DIAGNOSTIC LOT HYBRIDE\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "                if extract_tongue:\n",
        "                    print(f\"\\nD√©tection langue:\")\n",
        "                    print(f\"  - Langues d√©tect√©es: {tongue_detection_stats['detected']}\")\n",
        "                    print(f\"  - Non d√©tect√©es: {tongue_detection_stats['not_detected']}\")\n",
        "\n",
        "                total = len(images)\n",
        "                print(\"\\nR√©sultats diagnostic:\")\n",
        "                for stage in ['healthy', 'early', 'advanced']:\n",
        "                    count = results_summary.get(stage, 0)\n",
        "                    avg_conf = np.mean(confidence_scores[stage]) if confidence_scores[stage] else 0\n",
        "                    percentage = (count / total) * 100\n",
        "\n",
        "                    print(f\"{stage.upper()}: {count} images ({percentage:.1f}%)\")\n",
        "                    print(f\"  Confiance moyenne: {avg_conf:.2%}\")\n",
        "\n",
        "                # Sauvegarder r√©sultats d√©taill√©s\n",
        "                df = pd.DataFrame(detailed_results)\n",
        "                results_file = Path(CONFIG['results_dir']) / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "                df.to_csv(results_file, index=False)\n",
        "                print(f\"\\nüìÑ R√©sultats d√©taill√©s: {results_file}\")\n",
        "\n",
        "                # Nettoyer fichiers temporaires\n",
        "                if extract_tongue:\n",
        "                    cleanup = input(\"\\nNettoyer fichiers temporaires? (o/n) [o]: \").strip().lower()\n",
        "                    if cleanup != 'n':\n",
        "                        hybrid_system.tongue_detector.cleanup_temp_files()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå ERREUR: {e}\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\nüìä EVALUATION COMPARATIVE\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez comparer performances avec/sans extraction langue\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"\\nüéØ ANALYSE FEATURES IMPORTANTES\")\n",
        "            print(\"Fonctionnalit√© √† impl√©menter...\")\n",
        "            # Ici vous pouvez analyser impact de l'extraction langue sur features\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(\"\\nüëã Au revoir! Merci d'avoir utilis√© le syst√®me hybride!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main_hybrid()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n‚ö†Ô∏è Interruption utilisateur\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERREUR CRITIQUE: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlpYSrnjhkvT",
        "outputId": "05570d91-3a3d-44a0-9576-4568ddda40eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SYSTEME HYBRIDE YOLO + CLASSIFICATION ML - DIAGNOSTIC MTC\n",
            "Avec D√©tection Automatique de Langue\n",
            "SMAILI Maya & MORSLI Manel - UMMTO 2024/2025\n",
            "================================================================================\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 1\n",
            "\n",
            "üîÑ ENTRAINEMENT SYSTEME HYBRIDE\n",
            "Chemin mod√®le YOLO pathologies: /content/mon_modele.pt\n",
            "Chemin mod√®le YOLO langue (Enter pour segmentation couleur): /content/bestYolo8.pt\n",
            "Dossier images d'entra√Ænement: /content/train/train/images\n",
            "Extraire langue avant analyse? (o/n) [o]: o\n",
            "PREPARATION DES DONNEES D'ENTRAINEMENT\n",
            "============================================================\n",
            "Images trouv√©es: 80\n",
            "Distribution des labels:\n",
            "  - healthy: 38\n",
            "  - advanced: 19\n",
            "  - early: 23\n",
            "\n",
            "Extraction des features...\n",
            "  Progression: 0/80\n",
            "  Progression: 10/80\n",
            "  Progression: 20/80\n",
            "  Progression: 30/80\n",
            "  Progression: 40/80\n",
            "  Progression: 50/80\n",
            "  Progression: 60/80\n",
            "  Progression: 70/80\n",
            "\n",
            "Features extraites: (80, 67)\n",
            "Features par image: 67\n",
            "\n",
            "ENTRAINEMENT DES CLASSIFICATEURS\n",
            "============================================================\n",
            "\n",
            "Entra√Ænement RandomForest...\n",
            "  Accuracy: 0.9375\n",
            "  CV Score: 0.7808 (+/- 0.1531)\n",
            "\n",
            "Rapport d√©taill√© RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    advanced       1.00      1.00      1.00         4\n",
            "       early       1.00      0.80      0.89         5\n",
            "     healthy       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.96      0.93      0.94        16\n",
            "weighted avg       0.95      0.94      0.94        16\n",
            "\n",
            "\n",
            "Entra√Ænement XGBoost...\n",
            "  Accuracy: 0.8125\n",
            "  CV Score: 0.8269 (+/- 0.1240)\n",
            "\n",
            "Entra√Ænement SVM...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7987 (+/- 0.1529)\n",
            "\n",
            "Entra√Ænement MLP...\n",
            "  Accuracy: 0.8750\n",
            "  CV Score: 0.7500 (+/- 0.1141)\n",
            "\n",
            "Entra√Ænement GradientBoosting...\n",
            "  Accuracy: 0.8125\n",
            "  CV Score: 0.7641 (+/- 0.1788)\n",
            "\n",
            "üèÜ MEILLEUR MODELE: XGBoost\n",
            "   Accuracy: 0.8125\n",
            "   CV Score: 0.8269\n",
            "\n",
            "Sauvegarde mod√®les dans mtc_classifiers\n",
            "‚úÖ Mod√®les sauvegard√©s\n",
            "\n",
            "‚úÖ ENTRAINEMENT TERMINE!\n",
            "Mod√®les sauvegard√©s dans: mtc_classifiers\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO pathologies: /content/mon_modele.pt\n",
            "Chemin mod√®le YOLO langue (Enter pour segmentation couleur): /content/bestYolo8.pt\n",
            "Chemin image: /content/WhatsApp Image 2025-06-22 √† 00.01.46_3c8927f7.jpg\n",
            "Extraire langue avant analyse? (o/n) [o]: o\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "üîç D√©tection de la langue...\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image originale: WhatsApp Image 2025-06-22 √† 00.01.46_3c8927f7.jpg\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "üì∏ Image analys√©e: tongue_WhatsApp Image 2025-06-22 √† 00.01.46_3c8927f7_20250621_225944.jpg\n",
            "\n",
            "üéØ Pr√©diction: ADVANCED\n",
            "üìä Confiance: 92.61%\n",
            "ü§ñ Classificateur: XGBoost\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.9261 (92.61%)\n",
            "  - early: 0.0671 (6.71%)\n",
            "  - healthy: 0.0068 (0.68%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: advanced (0.757)\n",
            "  - XGBoost: advanced (0.926)\n",
            "  - SVM: advanced (0.794)\n",
            "  - MLP: advanced (1.000)\n",
            "  - GradientBoosting: advanced (1.000)\n",
            "\n",
            "üó∫Ô∏è Localisation par zones MTC:\n",
            "  - Foie-VB Droit: 10 d√©tection(s)\n",
            "  - Foie-VB Gauche: 10 d√©tection(s)\n",
            "  - Rate-Estomac: 7 d√©tection(s)\n",
            "  - Coeur-Poumon: 3 d√©tection(s)\n",
            "\n",
            "üìä Visualisation compl√®te: mtc_results/hybrid_mtc_WhatsApp Image 2025-06-22 √† 00.01.46_3c8927f7_20250621_225945.png\n",
            "\n",
            "Nettoyer fichiers temporaires? (o/n) [n]: o\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 5\n",
            "\n",
            "üéØ ANALYSE FEATURES IMPORTANTES\n",
            "Fonctionnalit√© √† impl√©menter...\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO pathologies: /content/mon_modele.pt\n",
            "Chemin mod√®le YOLO langue (Enter pour segmentation couleur): /content/bestYolo8.pt\n",
            "Chemin image: /content/train/train/images/ABC_11_png_segmented_jpg.rf.bab6fe1fdae5b285cbe2cafcfecabddd.jpg\n",
            "Extraire langue avant analyse? (o/n) [o]: o\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "üîç D√©tection de la langue...\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image originale: ABC_11_png_segmented_jpg.rf.bab6fe1fdae5b285cbe2cafcfecabddd.jpg\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "üì∏ Image analys√©e: tongue_ABC_11_png_segmented_jpg.rf.bab6fe1fdae5b285cbe2cafcfecabddd_20250621_230546.jpg\n",
            "\n",
            "üéØ Pr√©diction: ADVANCED\n",
            "üìä Confiance: 99.38%\n",
            "ü§ñ Classificateur: XGBoost\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.9938 (99.38%)\n",
            "  - early: 0.0043 (0.43%)\n",
            "  - healthy: 0.0018 (0.18%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: advanced (0.949)\n",
            "  - XGBoost: advanced (0.994)\n",
            "  - SVM: advanced (0.871)\n",
            "  - MLP: advanced (1.000)\n",
            "  - GradientBoosting: advanced (1.000)\n",
            "\n",
            "üó∫Ô∏è Localisation par zones MTC:\n",
            "  - Rate-Estomac: 10 d√©tection(s)\n",
            "  - Foie-VB Droit: 8 d√©tection(s)\n",
            "  - Foie-VB Gauche: 4 d√©tection(s)\n",
            "  - Coeur-Poumon: 3 d√©tection(s)\n",
            "  - Rein: 2 d√©tection(s)\n",
            "\n",
            "üìä Visualisation compl√®te: mtc_results/hybrid_mtc_ABC_11_png_segmented_jpg.rf.bab6fe1fdae5b285cbe2cafcfecabddd_20250621_230547.png\n",
            "\n",
            "Nettoyer fichiers temporaires? (o/n) [n]: o\n",
            "\n",
            "MENU SYSTEME HYBRIDE\n",
            "----------------------------------------\n",
            "1. Entra√Æner syst√®me hybride\n",
            "2. Diagnostic hybride (image unique)\n",
            "3. Diagnostic hybride (lot)\n",
            "4. √âvaluation comparative\n",
            "5. Analyser features importantes\n",
            "6. Quitter\n",
            "----------------------------------------\n",
            "Choix (1-6): 2\n",
            "\n",
            "üîç DIAGNOSTIC HYBRIDE\n",
            "Chemin mod√®le YOLO pathologies: /content/mon_modele.pt\n",
            "Chemin mod√®le YOLO langue (Enter pour segmentation couleur): /content/bestYolo8.pt\n",
            "Chemin image: /content/train/train/images/real_2_jpg_segmented_jpg.rf.b0c1f0bde7b7f6e3ba8dfee8c88f86bd.jpg\n",
            "Extraire langue avant analyse? (o/n) [o]: o\n",
            "Chargement mod√®les sauvegard√©s...\n",
            "‚úÖ Mod√®les charg√©s\n",
            "üîç D√©tection de la langue...\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC HYBRIDE YOLO + ML\n",
            "============================================================\n",
            "üì∏ Image originale: real_2_jpg_segmented_jpg.rf.b0c1f0bde7b7f6e3ba8dfee8c88f86bd.jpg\n",
            "‚úÖ Langue d√©tect√©e et extraite\n",
            "üì∏ Image analys√©e: tongue_real_2_jpg_segmented_jpg.rf.b0c1f0bde7b7f6e3ba8dfee8c88f86bd_20250621_230714.jpg\n",
            "\n",
            "üéØ Pr√©diction: HEALTHY\n",
            "üìä Confiance: 99.58%\n",
            "ü§ñ Classificateur: XGBoost\n",
            "\n",
            "üìà Probabilit√©s d√©taill√©es:\n",
            "  - advanced: 0.0012 (0.12%)\n",
            "  - early: 0.0030 (0.30%)\n",
            "  - healthy: 0.9958 (99.58%)\n",
            "\n",
            "üîÑ Pr√©dictions ensemble:\n",
            "  - RandomForest: healthy (0.994)\n",
            "  - XGBoost: healthy (0.996)\n",
            "  - SVM: healthy (0.929)\n",
            "  - MLP: healthy (1.000)\n",
            "  - GradientBoosting: healthy (1.000)\n",
            "\n",
            "üó∫Ô∏è Localisation par zones MTC:\n",
            "  - Rate-Estomac: 5 d√©tection(s)\n",
            "\n",
            "üìä Visualisation compl√®te: mtc_results/hybrid_mtc_real_2_jpg_segmented_jpg.rf.b0c1f0bde7b7f6e3ba8dfee8c88f86bd_20250621_230715.png\n"
          ]
        }
      ]
    }
  ]
}